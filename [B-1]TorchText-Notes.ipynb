{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "SEED = 515\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TorchText` before version 0.7\n",
    "Reference: https://github.com/pytorch/text/releases/tag/v0.7.0-rc3\n",
    "\n",
    "## Build a Dataset Manually\n",
    "Among the main concepts of `TorchText`, `Field` is the one that defines how data should be processed.  \n",
    "The `Field` class couples tokenization, vocabularies, splitting, batching and sampling, padding, and numericalization all together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, LabelField, Example, Dataset, BucketIterator\n",
    "\n",
    "TEXT = Field(tokenize='spacy', tokenizer_language='en_core_web_sm')\n",
    "GENDER = Field(sequential=False)\n",
    "LABEL = LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<torchtext.data.example.Example object at 0x00000160AC51ECA0>\n['I', 'like', 'this', 'film', '.']\nf\npos\n"
    }
   ],
   "source": [
    "# Example from dict\n",
    "fields = {'T': ('text', TEXT), \n",
    "          'G': ('gender', GENDER), \n",
    "          'L': ('label', LABEL)}\n",
    "raw_ex = {'T': \"I like this film.\", \n",
    "          'G': \"f\", \n",
    "          'L': \"pos\"}\n",
    "\n",
    "ex = Example.fromdict(raw_ex, fields)\n",
    "print(ex)\n",
    "print(ex.text)\n",
    "print(ex.gender)\n",
    "print(ex.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<torchtext.data.example.Example object at 0x00000160AB65CB80>\n['I', 'like', 'this', 'film', '.']\nf\npos\n"
    }
   ],
   "source": [
    "# Example from list\n",
    "fields = [('text', TEXT), ('gender', GENDER), ('label', LABEL)]\n",
    "raw_ex = [\"I like this film.\", \"f\", \"pos\"]\n",
    "\n",
    "ex = Example.fromlist(raw_ex, fields)\n",
    "print(ex)\n",
    "print(ex.text)\n",
    "print(ex.gender)\n",
    "print(ex.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<torchtext.data.dataset.Dataset object at 0x00000160AC51EE80>\n<torchtext.data.example.Example object at 0x00000160AC51EBB0>\n['I', 'hate', 'it', '.']\nf\nneg\n"
    }
   ],
   "source": [
    "# Create a Dataset\n",
    "fields = [('text', TEXT), ('gender', GENDER), ('label', LABEL)]\n",
    "raw_data = [[\"I like this film.\", \"f\", \"pos\"], \n",
    "            [\"I hate it.\", \"f\", \"neg\"], \n",
    "            [\"I have no feelings about it.\", \"m\", \"neg\"], \n",
    "            [\"It is my best.\", \"m\", \"pos\"], \n",
    "            [\"My father loves it so much and I do think so.\", \"f\", \"pos\"]]\n",
    "\n",
    "examples = [Example.fromlist(d, fields) for d in raw_data]\n",
    "data = Dataset(examples, fields)\n",
    "print(data)\n",
    "print(data[1])\n",
    "print(data[1].text)\n",
    "print(data[1].gender)\n",
    "print(data[1].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(25, 3, 2)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "TEXT.build_vocab(data)\n",
    "GENDER.build_vocab(data)\n",
    "LABEL.build_vocab(data)\n",
    "len(TEXT.vocab), len(GENDER.vocab), len(LABEL.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 3,  3],\n        [15, 16],\n        [ 4, 22],\n        [ 2, 13],\n        [ 1,  8],\n        [ 1,  4],\n        [ 1,  2]], device='cuda:0')\ntensor([[ 7,  3],\n        [12, 18],\n        [19, 24],\n        [ 4, 14],\n        [ 5,  2],\n        [20,  1],\n        [ 9,  1],\n        [ 3,  1],\n        [11,  1],\n        [23,  1],\n        [ 5,  1],\n        [ 2,  1]], device='cuda:0')\ntensor([[ 6],\n        [17],\n        [21],\n        [10],\n        [ 2]], device='cuda:0')\n"
    }
   ],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "iterator = BucketIterator(data, batch_size=BATCH_SIZE, device=device, shuffle=True)\n",
    "\n",
    "for batch in iterator:\n",
    "    print(batch.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Embeddings Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'I': 0, 'love': 1, 'this': 2, 'film': 3, 'very': 4, 'much': 5, '.': 6}\n['I', 'love', 'this', 'film', 'very', 'much', '.']\ntensor([[-5.2200e-01, -1.0764e+00,  8.8916e-01,  2.6261e-01,  7.3789e-01],\n        [-4.6000e-05,  1.6979e+00, -2.0411e+00, -2.0144e-01,  9.1392e-01],\n        [ 1.3107e+00, -7.9961e-01, -1.4983e+00,  1.4374e+00,  2.1713e-01],\n        [ 6.4269e-01, -3.0231e+00,  1.1120e+00, -1.1176e-01,  7.4710e-01],\n        [-6.1633e-01, -1.6504e-01, -1.5072e-01,  8.6449e-01, -1.7347e+00],\n        [ 1.7514e+00, -9.4005e-01,  1.7255e+00,  6.8504e-01, -1.1134e-01],\n        [ 1.1694e+00, -2.1626e+00, -8.9035e-01,  1.2425e+00, -1.4998e-01]])\n"
    }
   ],
   "source": [
    "from torchtext.vocab import Vectors, Vocab\n",
    "\n",
    "text = \"I love this film very much .\"\n",
    "with open('assets/vector_cache/test-vecs.txt', 'w', encoding='utf-8') as f:\n",
    "    for token in text.split():\n",
    "        vec = [\"%.6f\" % vi for vi in np.random.randn(5)]\n",
    "        f.write(\" \".join([token] + vec))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "vecs = Vectors('test-vecs.txt', cache='assets/vector_cache')\n",
    "print(vecs.stoi)\n",
    "print(vecs.itos)\n",
    "print(vecs.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<torchtext.data.dataset.Dataset at 0x160ac51edf0>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Set `include_lengths=True` to return the text lengths too. \n",
    "TEXT = Field(tokenize='spacy', tokenizer_language='en_core_web_sm', include_lengths=True)\n",
    "GENDER = Field(sequential=False)\n",
    "LABEL = LabelField(dtype=torch.float)\n",
    "\n",
    "# Create a Dataset\n",
    "fields = [('text', TEXT), ('gender', GENDER), ('label', LABEL)]\n",
    "raw_data = [[\"I like this film.\", \"f\", \"pos\"], \n",
    "            [\"I hate it.\", \"f\", \"neg\"], \n",
    "            [\"I have no feelings about it.\", \"m\", \"neg\"], \n",
    "            [\"It is my best.\", \"m\", \"pos\"], \n",
    "            [\"My father loves it so much and I do think so.\", \"f\", \"pos\"]]\n",
    "\n",
    "examples = [Example.fromlist(d, fields) for d in raw_data]\n",
    "data = Dataset(examples, fields)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "None\n"
    }
   ],
   "source": [
    "TEXT.build_vocab(data)\n",
    "GENDER.build_vocab(data)\n",
    "LABEL.build_vocab(data)\n",
    "\n",
    "print(TEXT.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 1.1694, -2.1626, -0.8903,  1.2425, -0.1500],\n        [-0.5220, -1.0764,  0.8892,  0.2626,  0.7379],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.6427, -3.0231,  1.1120, -0.1118,  0.7471],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 1.7514, -0.9401,  1.7255,  0.6850, -0.1113],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 1.3107, -0.7996, -1.4983,  1.4374,  0.2171]])\n"
    }
   ],
   "source": [
    "# The missing tokens are initialized as zeros, or by `unk_init` if provided. \n",
    "TEXT.build_vocab(data, vectors=vecs)\n",
    "print(TEXT.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(tensor([[ 3,  3],\n        [15, 16],\n        [ 4, 22],\n        [ 2, 13],\n        [ 1,  8],\n        [ 1,  4],\n        [ 1,  2]], device='cuda:0'), tensor([4, 7], device='cuda:0'))\n(tensor([[ 7,  3],\n        [12, 18],\n        [19, 24],\n        [ 4, 14],\n        [ 5,  2],\n        [20,  1],\n        [ 9,  1],\n        [ 3,  1],\n        [11,  1],\n        [23,  1],\n        [ 5,  1],\n        [ 2,  1]], device='cuda:0'), tensor([12,  5], device='cuda:0'))\n(tensor([[ 6],\n        [17],\n        [21],\n        [10],\n        [ 2]], device='cuda:0'), tensor([5], device='cuda:0'))\n"
    }
   ],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "iterator = BucketIterator(data, batch_size=BATCH_SIZE, device=device, shuffle=True)\n",
    "\n",
    "# `batch.text` is now a tuple with the second element being the text lengths.\n",
    "for batch in iterator:\n",
    "    print(batch.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Dataset from `TorchText`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data import Field, LabelField, BucketIterator\n",
    "\n",
    "# Set `batch_first=True` in the `Field`.\n",
    "TEXT = Field(tokenize='spacy', tokenizer_language='en_core_web_sm', include_lengths=True, batch_first=True)\n",
    "LABEL = LabelField()\n",
    "\n",
    "train_data, test_data = torchtext.datasets.TREC.splits(TEXT, LABEL, fine_grained=False, root='assets/data')\n",
    "train_data, valid_data = train_data.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "defaultdict(None, {'ENTY': 0, 'HUM': 1, 'DESC': 2, 'NUM': 3, 'LOC': 4, 'ABBR': 5})\n"
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE, \n",
    "                 vectors=\"glove.6B.100d\", vectors_cache=\"assets/vector_cache\", \n",
    "                 unk_init=torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([[   4,   24,    3,  297,  552,  106,   18,    7,  286,   14,  552,    2],\n         [  26,    5, 3375,  677,    2,    1,    1,    1,    1,    1,    1,    1],\n         [  10,   22,   61,  443,   41,  156,   18,  107,   36,   13,  357,    2]],\n        device='cuda:0'),\n tensor([12,  5, 12], device='cuda:0'))"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# `Field.preprocess` has been called when building the dataset. \n",
    "# `Field.preprocess` includes `Field.preprocessing` passed by user. \n",
    "\n",
    "# `Field.process` process a batch of examples to create a torch.Tensor.\n",
    "# `Field.process` includes padding, numericalization, and postprocess (including `Field.postprocessing` passed by user) a batch and create a tensor.\n",
    "TEXT.process([train_data[0].text, train_data[1].text, train_data[2].text], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['What', 'do', 'the', 'letters', 'D.C.', 'stand', 'for', 'in', 'Washington', ',', 'D.C.', '?']\ntensor([[  4,  24,   3, 297, 552, 106,  18,   7, 286,  14, 552,   2]],\n       device='cuda:0')\ntensor([12], device='cuda:0')\n"
    }
   ],
   "source": [
    "ex = train_data[0]\n",
    "print(ex.text)\n",
    "# If `include_lengths=False`, it should be:  \n",
    "# `TEXT.numericalize([ex.text], device=device)`\n",
    "text, text_lens = TEXT.numericalize(([ex.text], [len(ex.text)]), device=device)\n",
    "print(text)\n",
    "print(text_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE, sort_within_batch=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `BucketIterator.splits`\n",
    "By default, the first dataset (`train_iterator`) would be shuffled, while the other datasets (`valid_iterator` and `test_iterator`) would be not shuffled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(11, device='cuda:0') tensor(11, device='cuda:0') tensor(11, device='cuda:0')\ntensor(16, device='cuda:0') tensor(16, device='cuda:0') tensor(15, device='cuda:0')\ntensor(6, device='cuda:0') tensor(6, device='cuda:0') tensor(5, device='cuda:0')\ntensor(9, device='cuda:0') tensor(9, device='cuda:0') tensor(9, device='cuda:0')\ntensor(20, device='cuda:0') tensor(20, device='cuda:0') tensor(17, device='cuda:0')\ntensor(11, device='cuda:0') tensor(11, device='cuda:0') tensor(11, device='cuda:0')\ntensor(10, device='cuda:0') tensor(10, device='cuda:0') tensor(10, device='cuda:0')\ntensor(15, device='cuda:0') tensor(15, device='cuda:0') tensor(14, device='cuda:0')\ntensor(10, device='cuda:0') tensor(10, device='cuda:0') tensor(10, device='cuda:0')\ntensor(14, device='cuda:0') tensor(14, device='cuda:0') tensor(13, device='cuda:0')\n"
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "    text, text_lens = batch.text\n",
    "    print(text_lens.max(), text_lens[0], text_lens[-1])\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(14, device='cuda:0') tensor(14, device='cuda:0') tensor(13, device='cuda:0')\ntensor(7, device='cuda:0') tensor(7, device='cuda:0') tensor(6, device='cuda:0')\ntensor(7, device='cuda:0') tensor(7, device='cuda:0') tensor(7, device='cuda:0')\ntensor(11, device='cuda:0') tensor(11, device='cuda:0') tensor(10, device='cuda:0')\ntensor(11, device='cuda:0') tensor(11, device='cuda:0') tensor(11, device='cuda:0')\ntensor(6, device='cuda:0') tensor(6, device='cuda:0') tensor(5, device='cuda:0')\ntensor(16, device='cuda:0') tensor(16, device='cuda:0') tensor(15, device='cuda:0')\ntensor(9, device='cuda:0') tensor(9, device='cuda:0') tensor(9, device='cuda:0')\ntensor(10, device='cuda:0') tensor(10, device='cuda:0') tensor(9, device='cuda:0')\ntensor(12, device='cuda:0') tensor(12, device='cuda:0') tensor(12, device='cuda:0')\n"
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "    text, text_lens = batch.text\n",
    "    print(text_lens.max(), text_lens[0], text_lens[-1])\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(5, device='cuda:0') tensor(5, device='cuda:0') tensor(3, device='cuda:0')\ntensor(7, device='cuda:0') tensor(7, device='cuda:0') tensor(6, device='cuda:0')\ntensor(7, device='cuda:0') tensor(7, device='cuda:0') tensor(7, device='cuda:0')\ntensor(8, device='cuda:0') tensor(8, device='cuda:0') tensor(7, device='cuda:0')\ntensor(9, device='cuda:0') tensor(9, device='cuda:0') tensor(8, device='cuda:0')\ntensor(9, device='cuda:0') tensor(9, device='cuda:0') tensor(9, device='cuda:0')\ntensor(10, device='cuda:0') tensor(10, device='cuda:0') tensor(9, device='cuda:0')\ntensor(11, device='cuda:0') tensor(11, device='cuda:0') tensor(10, device='cuda:0')\ntensor(12, device='cuda:0') tensor(12, device='cuda:0') tensor(11, device='cuda:0')\ntensor(13, device='cuda:0') tensor(13, device='cuda:0') tensor(12, device='cuda:0')\n"
    }
   ],
   "source": [
    "for i, batch in enumerate(valid_iterator):\n",
    "    text, text_lens = batch.text\n",
    "    print(text_lens.max(), text_lens[0], text_lens[-1])\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(5, device='cuda:0') tensor(5, device='cuda:0') tensor(3, device='cuda:0')\ntensor(7, device='cuda:0') tensor(7, device='cuda:0') tensor(6, device='cuda:0')\ntensor(7, device='cuda:0') tensor(7, device='cuda:0') tensor(7, device='cuda:0')\ntensor(8, device='cuda:0') tensor(8, device='cuda:0') tensor(7, device='cuda:0')\ntensor(9, device='cuda:0') tensor(9, device='cuda:0') tensor(8, device='cuda:0')\ntensor(9, device='cuda:0') tensor(9, device='cuda:0') tensor(9, device='cuda:0')\ntensor(10, device='cuda:0') tensor(10, device='cuda:0') tensor(9, device='cuda:0')\ntensor(11, device='cuda:0') tensor(11, device='cuda:0') tensor(10, device='cuda:0')\ntensor(12, device='cuda:0') tensor(12, device='cuda:0') tensor(11, device='cuda:0')\ntensor(13, device='cuda:0') tensor(13, device='cuda:0') tensor(12, device='cuda:0')\n"
    }
   ],
   "source": [
    "for i, batch in enumerate(valid_iterator):\n",
    "    text, text_lens = batch.text\n",
    "    print(text_lens.max(), text_lens[0], text_lens[-1])\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}