{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "SEED = 515\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TorchText` before version 0.7\n",
    "Reference: https://github.com/pytorch/text/releases/tag/v0.7.0-rc3\n",
    "\n",
    "## Build a Dataset Manually\n",
    "Among the main concepts of `TorchText`, `Field` is the one that defines how data should be processed.  \n",
    "The `Field` class couples tokenization, vocabularies, splitting, batching and sampling, padding, and numericalization all together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, LabelField, Example, Dataset, BucketIterator\n",
    "\n",
    "TEXT = Field(tokenize='spacy', tokenizer_language='en_core_web_sm')\n",
    "GENDER = Field(sequential=False)\n",
    "LABEL = LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<torchtext.data.example.Example object at 0x00000269321B6D60>\n['I', 'like', 'this', 'film', '.']\nf\npos\n"
    }
   ],
   "source": [
    "# Example from dict\n",
    "fields = {'T': ('text', TEXT), \n",
    "          'G': ('gender', GENDER), \n",
    "          'L': ('label', LABEL)}\n",
    "raw_ex = {'T': \"I like this film.\", \n",
    "          'G': \"f\", \n",
    "          'L': \"pos\"}\n",
    "\n",
    "ex = Example.fromdict(raw_ex, fields)\n",
    "print(ex)\n",
    "print(ex.text)\n",
    "print(ex.gender)\n",
    "print(ex.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<torchtext.data.example.Example object at 0x00000269321B63A0>\n['I', 'like', 'this', 'film', '.']\nf\npos\n"
    }
   ],
   "source": [
    "# Example from list\n",
    "fields = [('text', TEXT), ('gender', GENDER), ('label', LABEL)]\n",
    "raw_ex = [\"I like this film.\", \"f\", \"pos\"]\n",
    "\n",
    "ex = Example.fromlist(raw_ex, fields)\n",
    "print(ex)\n",
    "print(ex.text)\n",
    "print(ex.gender)\n",
    "print(ex.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<torchtext.data.dataset.Dataset object at 0x000002692C9829D0>\n<torchtext.data.example.Example object at 0x000002692C996760>\n['I', 'hate', 'it', '.']\nf\nneg\n"
    }
   ],
   "source": [
    "# Create a Dataset\n",
    "fields = [('text', TEXT), ('gender', GENDER), ('label', LABEL)]\n",
    "raw_data = [[\"I like this film.\", \"f\", \"pos\"], \n",
    "            [\"I hate it.\", \"f\", \"neg\"], \n",
    "            [\"I have no feelings about it.\", \"m\", \"neg\"], \n",
    "            [\"It is my best.\", \"m\", \"pos\"], \n",
    "            [\"My father loves it so much and I do think so.\", \"f\", \"pos\"]]\n",
    "\n",
    "examples = [Example.fromlist(d, fields) for d in raw_data]\n",
    "data = Dataset(examples, fields)\n",
    "print(data)\n",
    "print(data[1])\n",
    "print(data[1].text)\n",
    "print(data[1].gender)\n",
    "print(data[1].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(25, 3, 2)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "TEXT.build_vocab(data)\n",
    "GENDER.build_vocab(data)\n",
    "LABEL.build_vocab(data)\n",
    "len(TEXT.vocab), len(GENDER.vocab), len(LABEL.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 3,  3],\n        [15, 16],\n        [ 4, 22],\n        [ 2, 13],\n        [ 1,  8],\n        [ 1,  4],\n        [ 1,  2]])\ntensor([[ 7,  3],\n        [12, 18],\n        [19, 24],\n        [ 4, 14],\n        [ 5,  2],\n        [20,  1],\n        [ 9,  1],\n        [ 3,  1],\n        [11,  1],\n        [23,  1],\n        [ 5,  1],\n        [ 2,  1]])\ntensor([[ 6],\n        [17],\n        [21],\n        [10],\n        [ 2]])\n"
    }
   ],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "iterator = BucketIterator(data, batch_size=BATCH_SIZE, device=device, shuffle=True)\n",
    "\n",
    "for batch in iterator:\n",
    "    print(batch.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Embeddings Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "86%|████████▌ | 6/7 [00:00<00:00, 6011.90it/s]\n{'I': 0, 'love': 1, 'this': 2, 'film': 3, 'very': 4, 'much': 5, '.': 6}\n['I', 'love', 'this', 'film', 'very', 'much', '.']\ntensor([[-0.1316, -1.2163,  0.3154,  2.2605,  0.4316],\n        [-0.4608, -0.9925, -0.2819, -1.6757,  0.3488],\n        [ 0.9211, -0.0034, -1.7872, -0.5069, -0.2404],\n        [ 0.2009, -2.6882,  0.1634,  0.8077,  0.0838],\n        [-0.0382,  0.2052, -1.1867,  0.8228, -0.5860],\n        [ 0.7365,  0.3347,  1.6088, -0.4995,  0.4200],\n        [-1.1841,  0.9180,  1.0854, -0.3196, -1.1193]])\n"
    }
   ],
   "source": [
    "from torchtext.vocab import Vectors, Vocab\n",
    "\n",
    "text = \"I love this film very much .\"\n",
    "with open('assets/vector_cache/test-vecs.txt', 'w', encoding='utf-8') as f:\n",
    "    for token in text.split():\n",
    "        vec = [\"%.6f\" % vi for vi in np.random.randn(5)]\n",
    "        f.write(\" \".join([token] + vec))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "vecs = Vectors('test-vecs.txt', cache='assets/vector_cache')\n",
    "print(vecs.stoi)\n",
    "print(vecs.itos)\n",
    "print(vecs.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<torchtext.data.dataset.Dataset at 0x2692c982f70>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Set `include_lengths=True` to return the text lengths too. \n",
    "TEXT = Field(tokenize='spacy', tokenizer_language='en_core_web_sm', include_lengths=True)\n",
    "GENDER = Field(sequential=False)\n",
    "LABEL = LabelField(dtype=torch.float)\n",
    "\n",
    "# Create a Dataset\n",
    "fields = [('text', TEXT), ('gender', GENDER), ('label', LABEL)]\n",
    "raw_data = [[\"I like this film.\", \"f\", \"pos\"], \n",
    "            [\"I hate it.\", \"f\", \"neg\"], \n",
    "            [\"I have no feelings about it.\", \"m\", \"neg\"], \n",
    "            [\"It is my best.\", \"m\", \"pos\"], \n",
    "            [\"My father loves it so much and I do think so.\", \"f\", \"pos\"]]\n",
    "\n",
    "examples = [Example.fromlist(d, fields) for d in raw_data]\n",
    "data = Dataset(examples, fields)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "None\n"
    }
   ],
   "source": [
    "TEXT.build_vocab(data)\n",
    "GENDER.build_vocab(data)\n",
    "LABEL.build_vocab(data)\n",
    "\n",
    "print(TEXT.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [-1.1841,  0.9180,  1.0854, -0.3196, -1.1193],\n        [-0.1316, -1.2163,  0.3154,  2.2605,  0.4316],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.2009, -2.6882,  0.1634,  0.8077,  0.0838],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.7365,  0.3347,  1.6088, -0.4995,  0.4200],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.9211, -0.0034, -1.7872, -0.5069, -0.2404]])\n"
    }
   ],
   "source": [
    "# The missing tokens are initialized as zeros, or by `unk_init` if provided. \n",
    "TEXT.build_vocab(data, vectors=vecs)\n",
    "print(TEXT.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(tensor([[ 3,  3],\n        [15, 16],\n        [ 4, 22],\n        [ 2, 13],\n        [ 1,  8],\n        [ 1,  4],\n        [ 1,  2]]), tensor([4, 7]))\n(tensor([[ 7,  3],\n        [12, 18],\n        [19, 24],\n        [ 4, 14],\n        [ 5,  2],\n        [20,  1],\n        [ 9,  1],\n        [ 3,  1],\n        [11,  1],\n        [23,  1],\n        [ 5,  1],\n        [ 2,  1]]), tensor([12,  5]))\n(tensor([[ 6],\n        [17],\n        [21],\n        [10],\n        [ 2]]), tensor([5]))\n"
    }
   ],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "iterator = BucketIterator(data, batch_size=BATCH_SIZE, device=device, shuffle=True)\n",
    "\n",
    "# `batch.text` is now a tuple with the second element being the text lengths.\n",
    "for batch in iterator:\n",
    "    print(batch.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Dataset from `TorchText`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data import Field, LabelField, BucketIterator\n",
    "\n",
    "# Set `batch_first=True` in the `Field`.\n",
    "TEXT = Field(tokenize='spacy', tokenizer_language='en_core_web_sm', include_lengths=True, batch_first=True)\n",
    "LABEL = LabelField()\n",
    "\n",
    "train_data, test_data = torchtext.datasets.TREC.splits(TEXT, LABEL, fine_grained=False, root=\"assets/data\")\n",
    "train_data, valid_data = train_data.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "defaultdict(None, {'ENTY': 0, 'HUM': 1, 'DESC': 2, 'NUM': 3, 'LOC': 4, 'ABBR': 5})\n"
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE, \n",
    "                 vectors=\"glove.6B.100d\", vectors_cache=\"assets/vector_cache\", \n",
    "                 unk_init=torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([[   4,   24,    3,  297,  552,  106,   18,    7,  286,   14,  552,    2],\n         [  26,    5, 3375,  677,    2,    1,    1,    1,    1,    1,    1,    1],\n         [  10,   22,   61,  443,   41,  156,   18,  107,   36,   13,  357,    2]]),\n tensor([12,  5, 12]))"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# `Field.preprocess` has been called when building the dataset. \n",
    "# `Field.preprocess` includes `Field.preprocessing` passed by user. \n",
    "\n",
    "# `Field.process` process a batch of examples to create a torch.Tensor.\n",
    "# `Field.process` includes padding, numericalization, and postprocess (including `Field.postprocessing` passed by user) a batch and create a tensor.\n",
    "TEXT.process([train_data[0].text, train_data[1].text, train_data[2].text], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['What', 'do', 'the', 'letters', 'D.C.', 'stand', 'for', 'in', 'Washington', ',', 'D.C.', '?']\ntensor([[  4,  24,   3, 297, 552, 106,  18,   7, 286,  14, 552,   2]])\ntensor([12])\n"
    }
   ],
   "source": [
    "ex = train_data[0]\n",
    "print(ex.text)\n",
    "# If `include_lengths=False`, it should be:  \n",
    "# `TEXT.numericalize([ex.text], device=device)`\n",
    "text, text_lens = TEXT.numericalize(([ex.text], [len(ex.text)]), device=device)\n",
    "print(text)\n",
    "print(text_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE, sort_within_batch=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `BucketIterator.splits`\n",
    "By default, the first dataset (`train_iterator`) would be shuffled, while the other datasets (`valid_iterator` and `test_iterator`) would be not shuffled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(11) tensor(11) tensor(11)\ntensor(16) tensor(16) tensor(15)\ntensor(6) tensor(6) tensor(5)\ntensor(9) tensor(9) tensor(9)\ntensor(20) tensor(20) tensor(17)\ntensor(11) tensor(11) tensor(11)\ntensor(10) tensor(10) tensor(10)\ntensor(15) tensor(15) tensor(14)\ntensor(10) tensor(10) tensor(10)\ntensor(14) tensor(14) tensor(13)\n"
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "    text, text_lens = batch.text\n",
    "    print(text_lens.max(), text_lens[0], text_lens[-1])\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(14) tensor(14) tensor(13)\ntensor(7) tensor(7) tensor(6)\ntensor(7) tensor(7) tensor(7)\ntensor(11) tensor(11) tensor(10)\ntensor(11) tensor(11) tensor(11)\ntensor(6) tensor(6) tensor(5)\ntensor(16) tensor(16) tensor(15)\ntensor(9) tensor(9) tensor(9)\ntensor(10) tensor(10) tensor(9)\ntensor(12) tensor(12) tensor(12)\n"
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "    text, text_lens = batch.text\n",
    "    print(text_lens.max(), text_lens[0], text_lens[-1])\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(5) tensor(5) tensor(3)\ntensor(7) tensor(7) tensor(6)\ntensor(7) tensor(7) tensor(7)\ntensor(8) tensor(8) tensor(7)\ntensor(9) tensor(9) tensor(8)\ntensor(9) tensor(9) tensor(9)\ntensor(10) tensor(10) tensor(9)\ntensor(11) tensor(11) tensor(10)\ntensor(12) tensor(12) tensor(11)\ntensor(13) tensor(13) tensor(12)\n"
    }
   ],
   "source": [
    "for i, batch in enumerate(valid_iterator):\n",
    "    text, text_lens = batch.text\n",
    "    print(text_lens.max(), text_lens[0], text_lens[-1])\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(5) tensor(5)tensor(3)\ntensor(7) tensor(7) tensor(6)\ntensor(7) tensor(7) tensor(7)\ntensor(8) tensor(8) tensor(7)\ntensor(9) tensor(9) tensor(8)\ntensor(9) tensor(9) tensor(9)\ntensor(10) tensor(10) tensor(9)\ntensor(11) tensor(11) tensor(10)\ntensor(12) tensor(12) tensor(11)\ntensor(13) tensor(13) tensor(12)\n"
    }
   ],
   "source": [
    "for i, batch in enumerate(valid_iterator):\n",
    "    text, text_lens = batch.text\n",
    "    print(text_lens.max(), text_lens[0], text_lens[-1])\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}