{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "SEED = 515\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "30522\n"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# tokenizer.save_pretrained('./transformers_cache/bert-base-uncased/')\n",
    "tokenizer = BertTokenizer.from_pretrained('./transformers_cache/bert-base-uncased/')\n",
    "print(len(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['hello', 'world', 'how', 'are', 'you', '?']\n[7592, 2088, 2129, 2024, 2017, 1029]\n[101, 7592, 2088, 2129, 2024, 2017, 1029, 102]\n"
    }
   ],
   "source": [
    "# This will tokenize and lower case the data in a way that is consistent with the pre-trained transformer model.\n",
    "text = \"Hello WORLD how ARE yoU?\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)\n",
    "\n",
    "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(indexes)\n",
    "\n",
    "indexes = tokenizer.encode(text, add_special_tokens=True)\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[CLS] [SEP] [PAD] [UNK]\n"
    }
   ],
   "source": [
    "# `cls_token`: The classifier token which is used when doing sequence classification (classification of the whole\n",
    "# sequence instead of per-token classification). It is the first token of the sequence when built with special tokens.\n",
    "init_token = tokenizer.cls_token\n",
    "# `sep_token`: The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences\n",
    "# for sequence classification or for a text and a question for question answering. It is also used as the last token of \n",
    "# a sequence built with special tokens.\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "101 102 0 100\n"
    }
   ],
   "source": [
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "512\n"
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "print(max_input_length)\n",
    "\n",
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "Now we define our fields. The transformer expects the batch dimension to be first, so we set `batch_first = True`. As we already have the vocabulary for our text, provided by the transformer we set `use_vocab = False` to tell torchtext that we'll be handling the vocabulary side of things. We pass our `tokenize_and_cut` function as the tokenizer. The `preprocessing` argument is a function that takes in the example after it has been tokenized, this is where we will convert the tokens to their indexes. Finally, we define the special tokens - making note that we are defining them to be their index value and not their string value, i.e. `100` instead of `[UNK]`. This is because the sequences will already be converted into indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data import Field, LabelField, BucketIterator\n",
    "\n",
    "# `use_vocab`: Whether to use a Vocab object. If False, the data in this field should already be numerical.\n",
    "TEXT = Field(batch_first=True, use_vocab=False, \n",
    "             tokenize=tokenize_and_cut, preprocessing=tokenizer.convert_tokens_to_ids, \n",
    "             init_token=init_token_idx, eos_token=eos_token_idx, pad_token=pad_token_idx, unk_token=unk_token_idx,\n",
    "             include_lengths=True)\n",
    "LABEL = LabelField(dtype=torch.float)\n",
    "\n",
    "train_data, test_data = torchtext.datasets.IMDB.splits(TEXT, LABEL, root='data')\n",
    "train_data, valid_data = train_data.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[2045, 2003, 1037, 2466, 1006, 4298, 9706, 10085, 2854, 21890, 2140, 1007, 2055, 2019, 3863, 2090, 5503, 12688, 1998, 6609]\n['there', 'is', 'a', 'story', '(', 'possibly', 'ap', '##oc', '##ry', '##pha', '##l', ')', 'about', 'an', 'exchange', 'between', 'bruce', 'willis', 'and', 'terry']\npos\n"
    }
   ],
   "source": [
    "# Note: The text has already been numericalized. \n",
    "print(train_data[0].text[:20])\n",
    "print(tokenizer.convert_ids_to_tokens(train_data[0].text[:20]))\n",
    "print(train_data[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE, sort_within_batch=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[  101,  2517,  2011,  ...,  4528,  1012,   102],\n        [  101,  7570,  1011,  ...,  2012,  1012,   102],\n        [  101,  1045,  2134,  ..., 11741,   999,   102],\n        ...,\n        [  101,  2748,  1010,  ...,     0,     0,     0],\n        [  101,  2178,  2742,  ...,     0,     0,     0],\n        [  101,  2023,  2003,  ...,     0,     0,     0]], device='cuda:3')\ntensor([130, 130, 130, 130, 130, 130, 130, 129, 129, 129, 129, 129, 129, 129,\n        129, 129, 129, 129, 129, 129, 129, 129, 128, 128, 128, 128, 128, 128,\n        128, 128, 128, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127, 127,\n        127, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126, 126,\n        126, 126, 126, 126, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125,\n        125, 125, 125, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124, 124,\n        124, 124, 124, 124, 124, 123, 123, 123, 123, 123, 123, 123, 123, 123,\n        123, 123], device='cuda:3')\n"
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    break\n",
    "text, text_lens = batch.text\n",
    "print(text)\n",
    "print(text_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "`BertModel.forward`\n",
    "* Input\n",
    "    * `input_ids`: (batch, step)\n",
    "    * `attention_mask`: (batch, step)\n",
    "        * Mask to avoid performing attention on padding token indices  \n",
    "        * A `torch.FloatTensor` with values selected in `{0, 1}`; The value being `0` means `masked`, and the value being `1` means `not-masked` \n",
    "* Output\n",
    "    * `last_hidden_state`: (batch, step, hidden)\n",
    "        * Sequence of hidden-states at the output of the last layer of the model  \n",
    "    * `pooler_output`: (batch, hidden)\n",
    "        * Last layer hidden-state of the first token of the sequence (classification token)\n",
    "        * It will be further processed by a linear layer and a `tanh`, which was trained for next sentence prediction (classification) objective  \n",
    "    * `attentions`: tuple of (batch, head, step, step), returned when `config.output_attentions=True`  \n",
    "        * Attention weights after the `softmax`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "# bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "# bert.save_pretrained('./transformers_cache/bert-base-uncased/')\n",
    "\n",
    "# Set `output_attentions=True` to return attentions from `bert.forward`\n",
    "bert = BertModel.from_pretrained('./transformers_cache/bert-base-uncased/', output_attentions=True).to(device)\n",
    "bert.config.output_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([100, 130])\ntorch.Size([100, 130, 768])\ntorch.Size([100, 768])\n12 12\ntorch.Size([100, 12, 130, 130])\n"
    }
   ],
   "source": [
    "# mask: (batch, step)\n",
    "mask = (batch.text[0] != pad_token_idx).float()\n",
    "bert_outs, bert_pooled_outs, attens = bert(batch.text[0], attention_mask=mask)\n",
    "print(batch.text[0].size())\n",
    "print(bert_outs.size())\n",
    "print(bert_pooled_outs.size())\n",
    "\n",
    "print(len(attens), bert.config.num_hidden_layers)\n",
    "print(attens[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(3.5763e-07, device='cuda:3', grad_fn=<MaxBackward1>)\ntensor(True, device='cuda:3')\ntensor([[[0.0076, 0.0048, 0.0143,  ..., 0.0036, 0.0101, 0.0238],\n         [0.0106, 0.0048, 0.0036,  ..., 0.0175, 0.0078, 0.0051],\n         [0.0129, 0.0081, 0.0089,  ..., 0.0080, 0.0088, 0.0164],\n         ...,\n         [0.0006, 0.0076, 0.0031,  ..., 0.0118, 0.0027, 0.0055],\n         [0.0041, 0.0052, 0.0112,  ..., 0.0097, 0.0203, 0.0380],\n         [0.0071, 0.0037, 0.0085,  ..., 0.0057, 0.0112, 0.0555]],\n\n        [[0.0074, 0.0080, 0.0076,  ..., 0.0096, 0.0098, 0.0232],\n         [0.0021, 0.0058, 0.0039,  ..., 0.0011, 0.0021, 0.0042],\n         [0.0063, 0.0093, 0.0038,  ..., 0.0061, 0.0071, 0.0095],\n         ...,\n         [0.0066, 0.0044, 0.0098,  ..., 0.0183, 0.0155, 0.0082],\n         [0.0041, 0.0040, 0.0083,  ..., 0.0195, 0.0202, 0.0378],\n         [0.0072, 0.0052, 0.0077,  ..., 0.0069, 0.0112, 0.0559]],\n\n        [[0.0080, 0.0068, 0.0040,  ..., 0.0035, 0.0036, 0.0249],\n         [0.0182, 0.0128, 0.0190,  ..., 0.0117, 0.0164, 0.0074],\n         [0.0129, 0.0096, 0.0051,  ..., 0.0066, 0.0233, 0.0080],\n         ...,\n         [0.0047, 0.0054, 0.0037,  ..., 0.0098, 0.0211, 0.0060],\n         [0.0020, 0.0033, 0.0026,  ..., 0.0266, 0.0080, 0.0564],\n         [0.0074, 0.0087, 0.0043,  ..., 0.0048, 0.0096, 0.0573]],\n\n        ...,\n\n        [[0.0078, 0.0059, 0.0063,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0106, 0.0079, 0.0143,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0094, 0.0093, 0.0080,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0018, 0.0058, 0.0010,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0011, 0.0063, 0.0007,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0012, 0.0073, 0.0007,  ..., 0.0000, 0.0000, 0.0000]],\n\n        [[0.0073, 0.0188, 0.0084,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0238, 0.0083, 0.0097,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0072, 0.0109, 0.0070,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0020, 0.0032, 0.0108,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0012, 0.0027, 0.0109,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0012, 0.0031, 0.0113,  ..., 0.0000, 0.0000, 0.0000]],\n\n        [[0.0080, 0.0141, 0.0057,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0263, 0.0054, 0.0201,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0101, 0.0041, 0.0090,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0019, 0.0021, 0.0035,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0011, 0.0019, 0.0038,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0012, 0.0022, 0.0034,  ..., 0.0000, 0.0000, 0.0000]]],\n       device='cuda:3', grad_fn=<SelectBackward>)\n"
    }
   ],
   "source": [
    "# Check whether the attention is 0 on padding positions \n",
    "print((attens[0].sum(dim=-1) - 1).abs().max())\n",
    "print(((attens[0] != 0) == mask.view(mask.size(0), 1, 1, -1)).all())\n",
    "\n",
    "# Show the first head attention\n",
    "print(attens[0][:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[  101,  2517,  2011,  ...,  4528,  1012,   102],\n        [  101,  7570,  1011,  ...,  2012,  1012,   102],\n        [  101,  1045,  2134,  ..., 11741,   999,   102],\n        ...,\n        [  101,  2748,  1010,  ...,     0,     0,     0],\n        [  101,  2178,  2742,  ...,     0,     0,     0],\n        [  101,  2023,  2003,  ...,     0,     0,     0]], device='cuda:3')\ntensor([[[-5.8253e-01, -3.8436e-01, -6.2410e-02,  ...,  3.3739e-01,\n           8.8629e-01,  3.8037e-01],\n         [ 2.8909e-01,  1.5803e-01, -3.4007e-01,  ...,  2.7079e-01,\n           5.1954e-01,  4.0081e-01],\n         [-8.5276e-02,  1.0641e-01, -2.0069e-02,  ...,  7.3669e-01,\n          -4.0883e-02,  5.4355e-03],\n         ...,\n         [ 6.9121e-01, -3.9525e-01,  1.3359e-01,  ...,  6.2148e-01,\n           2.5162e-01,  5.7626e-01],\n         [-5.6310e-01, -9.6340e-01, -3.7813e-01,  ...,  4.7410e-01,\n           8.7770e-01, -5.9787e-01],\n         [ 1.2288e-01,  6.0441e-01, -6.8059e-02,  ...,  2.8875e-01,\n          -3.9896e-01, -1.7507e-01]],\n\n        [[-7.3105e-01,  2.2431e-02, -1.3906e-02,  ..., -1.7642e-01,\n           4.3288e-01,  4.5411e-01],\n         [-3.2437e-01, -1.4501e-01,  5.9316e-01,  ...,  6.3854e-01,\n           9.4420e-01, -4.9262e-03],\n         [-2.0951e-01,  9.1212e-02,  6.3461e-01,  ...,  8.5551e-01,\n           3.9616e-01, -1.3586e-02],\n         ...,\n         [-4.5696e-01, -1.2627e-01,  1.0039e+00,  ...,  4.8094e-02,\n           3.2494e-01, -1.5927e-02],\n         [-6.5487e-01, -9.7997e-01,  9.7242e-02,  ...,  7.5975e-01,\n           6.8971e-01, -2.7226e-01],\n         [-1.4038e-01,  6.1704e-01,  2.7410e-01,  ...,  4.1734e-01,\n          -5.4359e-01, -8.3761e-02]],\n\n        [[-1.9738e-02, -3.2695e-01, -6.4970e-02,  ..., -1.3987e-01,\n           5.8595e-01,  5.5909e-01],\n         [ 4.6216e-01, -2.6140e-01,  6.0471e-02,  ...,  5.9054e-02,\n           1.1004e+00,  3.8386e-01],\n         [ 2.5962e-02, -2.5160e-01, -8.9949e-02,  ..., -9.6543e-03,\n           2.8626e-01, -3.3520e-01],\n         ...,\n         [ 5.7929e-02, -3.8517e-01, -2.3703e-01,  ...,  1.3002e-01,\n          -5.0247e-01, -6.1729e-01],\n         [-5.4488e-01, -4.8196e-01, -5.3148e-01,  ...,  7.9929e-01,\n           4.6827e-01,  1.5824e-01],\n         [ 1.1587e-01,  1.7116e-01,  2.9206e-01,  ...,  6.0424e-01,\n           9.3968e-02,  8.7771e-02]],\n\n        ...,\n\n        [[-1.7010e-01, -3.1179e-02, -4.1611e-01,  ..., -2.3801e-01,\n           6.6098e-01,  6.7405e-01],\n         [ 6.3688e-01,  1.5912e-01, -1.4722e-01,  ...,  1.7757e-01,\n           1.4094e+00,  1.7857e-01],\n         [-2.8993e-01,  3.4918e-01,  6.0047e-01,  ..., -6.9065e-02,\n           6.4809e-01,  4.1619e-01],\n         ...,\n         [ 4.8827e-02, -1.9558e-01,  5.2835e-01,  ...,  2.1701e-01,\n           3.7172e-01,  3.2822e-01],\n         [ 2.9777e-01,  8.9152e-02,  4.5369e-01,  ...,  1.4341e-01,\n           1.5261e-01,  3.6218e-01],\n         [ 3.0933e-01, -9.6997e-02,  6.2812e-01,  ...,  1.3509e-01,\n           1.3000e-01,  3.1333e-01]],\n\n        [[-1.8242e-01, -4.0956e-01,  3.7462e-01,  ..., -5.4242e-02,\n           3.7008e-01,  5.2961e-01],\n         [-1.2889e-01, -1.1107e-01,  6.4486e-04,  ...,  6.1409e-01,\n           1.0223e+00,  1.4978e-01],\n         [-6.1919e-01,  1.0516e+00, -1.5916e-01,  ..., -1.2988e-01,\n          -8.1049e-02, -2.5618e-01],\n         ...,\n         [-1.9597e-02, -4.7143e-01,  7.4088e-01,  ...,  1.4923e-01,\n          -3.9852e-02,  2.4166e-04],\n         [-2.5096e-02, -7.3018e-02,  4.4589e-01,  ...,  1.2300e-02,\n           6.0729e-02,  5.6299e-01],\n         [ 9.7834e-02, -2.2877e-01,  7.9090e-01,  ...,  8.6959e-02,\n          -4.0951e-02,  3.4828e-01]],\n\n        [[-1.5269e-03, -2.6597e-01,  2.1540e-02,  ..., -1.5561e-02,\n           3.3611e-01,  5.6374e-01],\n         [-1.1406e-01, -1.2528e-01,  1.8844e-02,  ..., -4.2510e-01,\n           1.4415e+00,  4.8568e-02],\n         [-1.1137e-01, -4.1225e-01,  3.6676e-01,  ..., -2.4789e-01,\n           9.1847e-01,  8.0941e-01],\n         ...,\n         [ 9.4979e-02, -4.9127e-01,  6.7641e-01,  ...,  6.4032e-01,\n           2.3680e-01, -3.3035e-01],\n         [ 1.2720e-01, -1.7793e-01,  4.4246e-01,  ...,  1.9959e-01,\n           2.7602e-01,  3.0594e-01],\n         [ 2.4248e-01, -1.3010e-01,  7.7761e-01,  ...,  2.1694e-01,\n           7.3948e-02,  1.2530e-01]]], device='cuda:3',\n       grad_fn=<NativeLayerNormBackward>)\n"
    }
   ],
   "source": [
    "# The values at padding positions are NOT zeros? \n",
    "# Yes, but they will never pollute the non-padding positions, since the attentions are applied with masking. \n",
    "print(batch.text[0])\n",
    "print(bert_outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using an embedding layer to get embeddings for our text, we'll be using the pre-trained transformer model. These embeddings will then be fed into a GRU to produce a prediction for the sentiment of the input sentence. We get the embedding dimension size (called the `hidden_size`) from the transformer via its config attribute. The rest of the initialization is standard.\n",
    "\n",
    "Within the forward pass, we wrap the transformer in a `no_grad` to ensure no gradients are calculated over this part of the model. The transformer actually returns the embeddings for the whole sequence as well as a *pooled* output. The [documentation](https://huggingface.co/transformers/model_doc/bert.html#transformers.BertModel) states that the pooled output is \"usually not a good summary of the semantic content of the input, you’re often better with averaging or pooling the sequence of hidden-states for the whole input sequence\", hence we will not be using it. The rest of the forward pass is the standard implementation of a recurrent model, where we take the hidden state over the final time-step, and pass it through a linear layer to get our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, bert, hid_dim, out_dim, n_layers, bidirect, dropout):\n",
    "        super().__init__()\n",
    "        # Use `bert` to provide word embeddings. \n",
    "        self.bert = bert\n",
    "        emb_dim = bert.config.hidden_size\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, num_layers=n_layers, bidirectional=bidirect, batch_first=True, \n",
    "                          dropout=(0 if n_layers < 2 else dropout))\n",
    "        self.fc = nn.Linear((hid_dim*2 if bidirect else hid_dim), out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text, text_lens):\n",
    "        # text/mask: (step, batch)\n",
    "        with torch.no_grad():\n",
    "            mask = (text != self.bert.config.pad_token_id).float()\n",
    "            embedded, *_ = self.bert(text, attention_mask=mask)\n",
    "\n",
    "        # `<pad>` token: `bert.config.pad_token_id`\n",
    "        # Pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lens, batch_first=True)\n",
    "        # hidden: (num_layers*num_directions, batch, hid_dim)\n",
    "        packed_outs, hidden = self.rnn(packed_embedded)\n",
    "        # Unpack sequence, NOT used here. \n",
    "        # outs, out_lens = nn.utils.rnn.pad_packed_sequence(packed_outs, batch_first=True)\n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat([hidden[-2], hidden[-1]], dim=-1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1])\n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "109482240\n112241409\n"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Count trainable parameters. \n",
    "    \"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "HID_DIM = 256\n",
    "OUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECT = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "classifier = Classifier(bert, HID_DIM, OUT_DIM, N_LAYERS, BIDIRECT, DROPOUT).to(device)\n",
    "\n",
    "print(count_parameters(bert))\n",
    "print(count_parameters(classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2759169\n"
    }
   ],
   "source": [
    "# Freeze BERT parameters (NOT train them). \n",
    "for name, param in classifier.named_parameters():\n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad_(False)\n",
    "\n",
    "print(count_parameters(classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(classifier.parameters())\n",
    "# Binary cross entropy with logits. \n",
    "# The binary version of cross entropy loss. \n",
    "loss_func = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(classifier, iterator, optimizer, loss_func):\n",
    "    classifier.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for batch in iterator:\n",
    "        # Forward pass\n",
    "        text, text_lens = batch.text\n",
    "        preds = classifier(text, text_lens).squeeze(-1)\n",
    "        # Calculate loss\n",
    "        loss = loss_func(preds, batch.label)\n",
    "        # Backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Accumulate loss and acc\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += (torch.round(torch.sigmoid(preds)) == batch.label).sum().item() / preds.size(0)\n",
    "    return epoch_loss/len(iterator), epoch_acc/len(iterator)\n",
    "\n",
    "def eval_epoch(classifier, iterator, loss_func):\n",
    "    classifier.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            # Forward pass\n",
    "            text, text_lens = batch.text\n",
    "            preds = classifier(text, text_lens).squeeze(-1)\n",
    "            # Calculate loss\n",
    "            loss = loss_func(preds, batch.label)\n",
    "            # Accumulate loss and acc\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += (torch.round(torch.sigmoid(preds)) == batch.label).sum().item() / preds.size(0)\n",
    "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch: 01 | Epoch Time: 2m 36s\n\tTrain Loss: 0.403 | Train Acc: 81.67%\n\t Val. Loss: 0.262 |  Val. Acc: 89.29%\nEpoch: 02 | Epoch Time: 2m 36s\n\tTrain Loss: 0.251 | Train Acc: 90.15%\n\t Val. Loss: 0.273 |  Val. Acc: 88.71%\nEpoch: 03 | Epoch Time: 2m 36s\n\tTrain Loss: 0.206 | Train Acc: 92.02%\n\t Val. Loss: 0.210 |  Val. Acc: 91.81%\nEpoch: 04 | Epoch Time: 2m 36s\n\tTrain Loss: 0.175 | Train Acc: 93.47%\n\t Val. Loss: 0.204 |  Val. Acc: 91.84%\nEpoch: 05 | Epoch Time: 2m 36s\n\tTrain Loss: 0.159 | Train Acc: 94.05%\n\t Val. Loss: 0.213 |  Val. Acc: 91.95%\n"
    }
   ],
   "source": [
    "import time\n",
    "N_EPOCHS = 5\n",
    "best_valid_loss = np.inf\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    t0 = time.time()\n",
    "    train_loss, train_acc = train_epoch(classifier, train_iterator, optimizer, loss_func)\n",
    "    valid_loss, valid_acc = eval_epoch(classifier, valid_iterator, loss_func)\n",
    "    epoch_secs = time.time() - t0\n",
    "\n",
    "    epoch_mins, epoch_secs = int(epoch_secs // 60), int(epoch_secs % 60)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(classifier.state_dict(), 'models/tut6-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Val. Loss: 0.204 | Val. Acc: 91.84%\nTest Loss: 0.190 | Test Acc: 92.57%\n"
    }
   ],
   "source": [
    "classifier.load_state_dict(torch.load('models/tut6-model.pt'))\n",
    "\n",
    "valid_loss, valid_acc = eval_epoch(classifier, valid_iterator, loss_func)\n",
    "test_loss, test_acc = eval_epoch(classifier, test_iterator, loss_func)\n",
    "\n",
    "print(f'Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_senti(classifier, tokenizer, sentence):\n",
    "    classifier.eval()\n",
    "    indexed = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "    lens = len(indexed)\n",
    "\n",
    "    # Note: `batch_first=True`\n",
    "    indexed = torch.tensor(indexed, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    lens = torch.tensor(lens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    pred = torch.sigmoid(classifier(indexed, lens)).round().type(torch.long)\n",
    "    return LABEL.vocab.itos[pred.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'pos'"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "predict_senti(classifier, tokenizer, \"This is a good film.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'neg'"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "predict_senti(classifier, tokenizer, \"This film is terrible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}