{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "SEED = 515\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TorchText` after version 0.7\n",
    "Reference: https://github.com/pytorch/text/releases/tag/v0.7.0-rc3\n",
    "\n",
    "## Build a Dataset Manually\n",
    "### Define `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Refs:\n",
    "    https://github.com/pytorch/text/blob/master/torchtext/experimental/datasets/text_classification.py\n",
    "    \"\"\"\n",
    "    def __init__(self, data, vocab, transforms):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.transforms = transforms  # (label_transforms, tokens_transforms)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        text, label = self.data[i]\n",
    "        return (self.transforms[0](text), self.transforms[1](label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_labels(self):\n",
    "        labels = []\n",
    "        for text, label in self.data:\n",
    "            labels.apppend(self.transforms[1](label))\n",
    "        return set(labels)\n",
    "\n",
    "    def get_vocab(self):\n",
    "        return self.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('.', 5), ('I', 4), ('it', 3), ('so', 2), ('like', 1)]\n[('pos', 3), ('neg', 2)]\n"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize(text):\n",
    "    return [tok.text for tok in nlp(text)]\n",
    "\n",
    "raw_data = [[\"I like this film.\", \"pos\"], \n",
    "            [\"I hate it.\", \"neg\"], \n",
    "            [\"I have no feelings about it.\", \"neg\"], \n",
    "            [\"It is my best.\", \"pos\"], \n",
    "            [\"My father loves it so much and I do think so.\", \"pos\"]]\n",
    "\n",
    "token_counter = Counter()\n",
    "label_counter = Counter()\n",
    "for text, label in raw_data:\n",
    "    token_counter.update(tokenize(text))\n",
    "    label_counter.update([label])\n",
    "\n",
    "print(token_counter.most_common(5))\n",
    "print(label_counter.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'I': 0, 'love': 1, 'this': 2, 'film': 3, 'very': 4, 'much': 5, '.': 6}\n['I', 'love', 'this', 'film', 'very', 'much', '.']\ntensor([[-0.1316, -1.2163,  0.3154,  2.2605,  0.4316],\n        [-0.4608, -0.9925, -0.2819, -1.6757,  0.3488],\n        [ 0.9211, -0.0034, -1.7872, -0.5069, -0.2404],\n        [ 0.2009, -2.6882,  0.1634,  0.8077,  0.0838],\n        [-0.0382,  0.2052, -1.1867,  0.8228, -0.5860],\n        [ 0.7365,  0.3347,  1.6088, -0.4995,  0.4200],\n        [-1.1841,  0.9180,  1.0854, -0.3196, -1.1193]])\n"
    }
   ],
   "source": [
    "from torchtext.vocab import Vocab, Vectors\n",
    "\n",
    "vecs = Vectors('test-vecs.txt', cache='assets/vector_cache')\n",
    "print(vecs.stoi)\n",
    "print(vecs.itos)\n",
    "print(vecs.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('.', 5), ('I', 4), ('it', 3), ('so', 2), ('like', 1)]\n['<unk>', '<pad>', '.', 'I', 'it', 'so', 'It', 'My', 'about', 'and', 'best', 'do', 'father', 'feelings', 'film', 'hate', 'have', 'is', 'like', 'loves', 'much', 'my', 'no', 'think', 'this']\n['pos', 'neg']\n"
    }
   ],
   "source": [
    "vocab = Vocab(token_counter, vectors=vecs)\n",
    "print(vocab.freqs.most_common(5))\n",
    "print(vocab.itos)\n",
    "\n",
    "label_vocab = Vocab(label_counter, specials=())\n",
    "print(label_vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [-1.1841,  0.9180,  1.0854, -0.3196, -1.1193],\n        [-0.1316, -1.2163,  0.3154,  2.2605,  0.4316],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.2009, -2.6882,  0.1634,  0.8077,  0.0838],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.7365,  0.3347,  1.6088, -0.4995,  0.4200],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.9211, -0.0034, -1.7872, -0.5069, -0.2404]])"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "vocab.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `transforms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "([3, 18, 24, 14, 2], 0)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from torchtext.experimental.functional import vocab_func, sequential_transforms\n",
    "\n",
    "dataset = MyDataset(raw_data, vocab, \n",
    "                    (sequential_transforms(tokenize, vocab_func(vocab)), \n",
    "                     lambda x: label_vocab.stoi[x]))\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[3, 18, 24, 14, 2], [3, 15, 4, 2]]\n[0, 1]\n"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = [], []\n",
    "    for text, label in batch:\n",
    "        texts.append(text)\n",
    "        labels.append(label)\n",
    "    return texts, labels\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn)\n",
    "for idx, (texts, labels) in enumerate(train_loader):\n",
    "    break\n",
    "\n",
    "print(texts)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[3, 18, 24, 14, 2, 1, 1, 1, 1, 1], [3, 15, 4, 2, 1, 1, 1, 1, 1, 1]]\n"
    }
   ],
   "source": [
    "def pad(texts, padding_idx=0, length=None):\n",
    "    maxlen = max(len(text) for text in texts)\n",
    "    length = maxlen if length is None else max(length, maxlen)\n",
    "\n",
    "    return [text + [padding_idx] * (length-len(text)) for text in texts]\n",
    "\n",
    "texts = pad(texts, padding_idx=vocab.stoi['<pad>'], length=10)\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 3, 18, 24, 14,  2,  1,  1,  1,  1,  1],\n        [ 3, 15,  4,  2,  1,  1,  1,  1,  1,  1]])\ntensor([0, 1])\n"
    }
   ],
   "source": [
    "print(torch.tensor(texts))\n",
    "print(torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching, Padding, To-Tensor in One `collate_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 3, 18, 24, 14,  2,  1,  1,  1,  1,  1],\n        [ 3, 15,  4,  2,  1,  1,  1,  1,  1,  1]])\ntensor([0, 1])\n"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def great_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Batching, padding and to-tensor together.\n",
    "    \"\"\"\n",
    "    texts, labels = [], []\n",
    "    for text, label in batch:\n",
    "        texts.append(text)\n",
    "        labels.append(label)\n",
    "\n",
    "    texts = pad(texts, padding_idx=vocab.stoi['<pad>'], length=10)\n",
    "    return torch.tensor(texts), torch.tensor(labels)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=2, collate_fn=great_collate_fn)\n",
    "for idx, (texts, labels) in enumerate(train_loader):\n",
    "    break\n",
    "\n",
    "print(texts)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Dataset from `TorchText`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "25000lines [00:05, 4656.67lines/s]\n"
    }
   ],
   "source": [
    "from torchtext.experimental.datasets import IMDB\n",
    "train_data, test_data = IMDB(ngrams=3, root=\"assets/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = [], []\n",
    "    for label, txt in batch:\n",
    "        texts.append(txt)\n",
    "        labels.append(label)\n",
    "    return texts, labels\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8, collate_fn=collate_fn)\n",
    "for idx, (texts, labels) in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'list'> 8\n<class 'torch.Tensor'> torch.Size([948])\n<class 'torch.Tensor'> torch.Size([759])\n<class 'torch.Tensor'> torch.Size([300])\n"
    }
   ],
   "source": [
    "print(type(texts), len(texts))\n",
    "\n",
    "print(type(texts[0]), texts[0].size())\n",
    "print(type(texts[1]), texts[1].size())\n",
    "print(type(texts[2]), texts[2].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'list'> 8\n<class 'torch.Tensor'> torch.Size([])\n<class 'torch.Tensor'> torch.Size([])\n<class 'torch.Tensor'> torch.Size([])\n"
    }
   ],
   "source": [
    "print(type(labels), len(labels))\n",
    "\n",
    "print(type(labels[0]), labels[0].size())\n",
    "print(type(labels[1]), labels[1].size())\n",
    "print(type(labels[2]), labels[2].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}