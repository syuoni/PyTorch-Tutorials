{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "SEED = 515\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TorchText` after version 0.7\n",
    "Reference: https://github.com/pytorch/text/releases/tag/v0.7.0-rc3\n",
    "\n",
    "## Build a Dataset Manually\n",
    "### Define `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Refs:\n",
    "    https://github.com/pytorch/text/blob/master/torchtext/experimental/datasets/text_classification.py\n",
    "    \"\"\"\n",
    "    def __init__(self, data, vocab, transforms):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.transforms = transforms  # (label_transforms, tokens_transforms)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        text, label = self.data[i]\n",
    "        return (self.transforms[0](text), self.transforms[1](label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_labels(self):\n",
    "        labels = []\n",
    "        for text, label in self.data:\n",
    "            labels.apppend(self.transforms[1](label))\n",
    "        return set(labels)\n",
    "\n",
    "    def get_vocab(self):\n",
    "        return self.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('.', 5), ('I', 4), ('it', 3), ('so', 2), ('like', 1)]\n[('pos', 3), ('neg', 2)]\n"
    }
   ],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize(text):\n",
    "    return [tok.text for tok in nlp(text)]\n",
    "\n",
    "raw_data = [[\"I like this film.\", \"pos\"], \n",
    "            [\"I hate it.\", \"neg\"], \n",
    "            [\"I have no feelings about it.\", \"neg\"], \n",
    "            [\"It is my best.\", \"pos\"], \n",
    "            [\"My father loves it so much and I do think so.\", \"pos\"]]\n",
    "\n",
    "token_counter = Counter()\n",
    "label_counter = Counter()\n",
    "for text, label in raw_data:\n",
    "    token_counter.update(tokenize(text))\n",
    "    label_counter.update([label])\n",
    "\n",
    "print(token_counter.most_common(5))\n",
    "print(label_counter.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "8\n0\n['<unk>', '<pad>', '.', 'I', 'it', 'so', 'like', 'this', 'film', 'hate', 'have', 'no', 'feelings', 'about', 'It', 'is', 'my', 'best', 'My', 'father', 'loves', 'much', 'and', 'do', 'think']\n{'<unk>': 0, '<pad>': 1, '.': 2, 'I': 3, 'it': 4, 'so': 5, 'like': 6, 'this': 7, 'film': 8, 'hate': 9, 'have': 10, 'no': 11, 'feelings': 12, 'about': 13, 'It': 14, 'is': 15, 'my': 16, 'best': 17, 'My': 18, 'father': 19, 'loves': 20, 'much': 21, 'and': 22, 'do': 23, 'think': 24}\n"
    }
   ],
   "source": [
    "from torchtext.experimental.vocab import Vocab\n",
    "\n",
    "# `Counter.most_common` returns the tuple list sorted by frequcies. \n",
    "vocab = Vocab(OrderedDict([('<unk>', 100), ('<pad>', 100)] + token_counter.most_common()))\n",
    "\n",
    "print(vocab['film'])\n",
    "print(vocab['a_unk_token'])\n",
    "\n",
    "print(vocab.get_itos())\n",
    "print(vocab.get_stoi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "7\ntensor([ 2.2844,  1.1930,  0.0323, -0.5821,  0.7174])\ntensor([0., 0., 0., 0., 0.])\n"
    }
   ],
   "source": [
    "from torchtext.experimental.vectors import Vectors\n",
    "\n",
    "text = \"I love this film very much.\"\n",
    "tokens = tokenize(text)\n",
    "vec_values = torch.randn(len(tokens), 5)\n",
    "vecs = Vectors(tokens, vec_values)\n",
    "\n",
    "print(len(vecs))\n",
    "print(vecs[\"film\"])\n",
    "print(vecs[\"a_unk_token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [-0.0578, -0.9896, -0.9021,  0.0657, -1.3600],\n        [-0.3902,  1.4256,  0.0491, -0.0559, -1.0172],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0143, -0.3039, -0.7228,  0.4080,  0.1864],\n        [ 2.2844,  1.1930,  0.0323, -0.5821,  0.7174],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.9438,  1.9114, -0.1822,  0.0917, -2.1669],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "vecs.lookup_vectors(vocab.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ".\ntensor([-0.0578, -0.9896, -0.9021,  0.0657, -1.3600])\nit\ntensor([0., 0., 0., 0., 0.])\n"
    }
   ],
   "source": [
    "idx = 2\n",
    "print(vocab.get_itos()[idx])\n",
    "print(vecs[vocab.get_itos()[idx]])\n",
    "\n",
    "idx = 4\n",
    "print(vocab.get_itos()[idx])\n",
    "print(vecs[vocab.get_itos()[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `transforms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'<pad>': 0, 'pos': 1, 'neg': 2}"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "idx2label = ['<pad>'] + list(label_counter.keys())\n",
    "\n",
    "label2idx = {label: i for i, label in enumerate(idx2label)}\n",
    "label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "([3, 6, 7, 8, 2], 1)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from torchtext.experimental.functional import vocab_func, sequential_transforms\n",
    "\n",
    "dataset = MyDataset(raw_data, vocab, \n",
    "                    (sequential_transforms(tokenize, vocab_func(vocab)), \n",
    "                     lambda x: label2idx[x]))\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[3, 6, 7, 8, 2], [3, 9, 4, 2]]\n[1, 2]\n"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = [], []\n",
    "    for text, label in batch:\n",
    "        texts.append(text)\n",
    "        labels.append(label)\n",
    "    return texts, labels\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn)\n",
    "for idx, (texts, labels) in enumerate(train_loader):\n",
    "    break\n",
    "\n",
    "print(texts)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[3, 6, 7, 8, 2, 1, 1, 1, 1, 1], [3, 9, 4, 2, 1, 1, 1, 1, 1, 1]]\n"
    }
   ],
   "source": [
    "def pad(texts, padding_idx=0, length=None):\n",
    "    maxlen = max(len(text) for text in texts)\n",
    "    length = maxlen if length is None else max(length, maxlen)\n",
    "\n",
    "    return [text + [padding_idx] * (length-len(text)) for text in texts]\n",
    "\n",
    "texts = pad(texts, padding_idx=vocab['<pad>'], length=10)\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[3, 6, 7, 8, 2, 1, 1, 1, 1, 1],\n        [3, 9, 4, 2, 1, 1, 1, 1, 1, 1]])\ntensor([1, 2])\n"
    }
   ],
   "source": [
    "print(torch.tensor(texts))\n",
    "print(torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching, Padding, To-Tensor in One `collate_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[3, 6, 7, 8, 2, 1, 1, 1, 1, 1],\n        [3, 9, 4, 2, 1, 1, 1, 1, 1, 1]])\ntensor([1, 2])\n"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def great_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Batching, padding and to-tensor together.\n",
    "    \"\"\"\n",
    "    texts, labels = [], []\n",
    "    for text, label in batch:\n",
    "        texts.append(text)\n",
    "        labels.append(label)\n",
    "\n",
    "    # It may be better to register the collate function as a method of Dataset\n",
    "    texts = pad(texts, padding_idx=vocab['<pad>'], length=10)\n",
    "    return torch.tensor(texts), torch.tensor(labels)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=2, collate_fn=great_collate_fn)\n",
    "for idx, (texts, labels) in enumerate(train_loader):\n",
    "    break\n",
    "\n",
    "print(texts)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Dataset from `TorchText`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "25000lines [00:05, 4643.70lines/s]\n"
    }
   ],
   "source": [
    "from torchtext.experimental.datasets import IMDB\n",
    "train_data, test_data = IMDB(ngrams=3, root=\"assets/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = [], []\n",
    "    for label, txt in batch:\n",
    "        texts.append(txt)\n",
    "        labels.append(label)\n",
    "    return texts, labels\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8, collate_fn=collate_fn)\n",
    "for idx, (texts, labels) in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'list'> 8\n<class 'torch.Tensor'> torch.Size([948])\n<class 'torch.Tensor'> torch.Size([759])\n<class 'torch.Tensor'> torch.Size([300])\n"
    }
   ],
   "source": [
    "print(type(texts), len(texts))\n",
    "\n",
    "print(type(texts[0]), texts[0].size())\n",
    "print(type(texts[1]), texts[1].size())\n",
    "print(type(texts[2]), texts[2].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[  13, 3857,   13,  ...,    1,    1,    1],\n        [  13,  401, 5144,  ...,    1,    1,    1],\n        [  63,   89,    8,  ...,    1,    1,    1],\n        ...,\n        [  13,   85,  471,  ...,    1,    1,    1],\n        [6688, 2336,    2,  ...,    1,    1,    1],\n        [  75,   13,  121,  ...,    1,    1,    1]])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "nn.utils.rnn.pad_sequence(texts, batch_first=True, padding_value=train_data.vocab['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'list'> 8\n<class 'torch.Tensor'> torch.Size([])\n<class 'torch.Tensor'> torch.Size([])\n<class 'torch.Tensor'> torch.Size([])\n"
    }
   ],
   "source": [
    "print(type(labels), len(labels))\n",
    "\n",
    "print(type(labels[0]), labels[0].size())\n",
    "print(type(labels[1]), labels[1].size())\n",
    "print(type(labels[2]), labels[2].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}