{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch tensor\n",
    "## Construct tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1.3696e+36, 7.5810e-43, 1.3696e+36, 7.5810e-43, 8.7441e-43],\n        [0.0000e+00, 8.7581e-43, 0.0000e+00, 1.9519e+36, 7.5810e-43]])\ntensor([[0.1845, 0.0280, 0.7416, 0.9247, 0.3055],\n        [0.8828, 0.4518, 0.2703, 0.4701, 0.6875]])\ntensor([[0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0]])\n"
    }
   ],
   "source": [
    "# Construct a tensor from shape\n",
    "x = torch.empty(2, 5)\n",
    "print(x)\n",
    "x = torch.rand(2, 5)\n",
    "print(x)\n",
    "x = torch.zeros(2, 5, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([5.5000, 3.0000])\ntensor(3)\n"
    }
   ],
   "source": [
    "# Construct a tensor from data\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)\n",
    "x = torch.tensor(3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([2])\ntorch.Size([])\ntorch.Size([2])\ntorch.Size([])\n"
    }
   ],
   "source": [
    "# Get size/shape\n",
    "# torch.Size is in fact a tuple, so it supports all tuple operations. \n",
    "print(torch.tensor([5.5, 3]).size())\n",
    "print(torch.tensor(3).size())\n",
    "\n",
    "# Numpy-like .shape\n",
    "print(torch.tensor([5.5, 3]).shape)\n",
    "print(torch.tensor(3).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([ 0.0000e+00,  0.0000e+00, -2.2324e-10])\n"
    }
   ],
   "source": [
    "# DO NOT use torch.Tensor (sometimes works like torch.empty)\n",
    "x = torch.Tensor(3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1.2339, 1.0062, 1.2969, 0.1664, 0.8805],\n        [0.7677, 0.3182, 1.0001, 0.5139, 0.8270]])\ntensor([[1.2339, 1.0062, 1.2969, 0.1664, 0.8805],\n        [0.7677, 0.3182, 1.0001, 0.5139, 0.8270]])\ntensor([[1.2339, 1.0062, 1.2969, 0.1664, 0.8805],\n        [0.7677, 0.3182, 1.0001, 0.5139, 0.8270]])\n"
    }
   ],
   "source": [
    "# Addition\n",
    "x = torch.rand(2, 5)\n",
    "y = torch.rand(2, 5)\n",
    "print(x + y)\n",
    "print(torch.add(x, y))\n",
    "\n",
    "res = torch.empty(2, 5)\n",
    "torch.add(x, y, out=res)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1.2339, 1.0062, 1.2969, 0.1664, 0.8805],\n        [0.7677, 0.3182, 1.0001, 0.5139, 0.8270]])\n"
    }
   ],
   "source": [
    "# In-place addition\n",
    "# Any operation that mutates a tensor in-place is post-fixed with an _. For example: x.copy_(y), x.t_(), will change x.\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1.0062, 0.3182])\n"
    }
   ],
   "source": [
    "# Numpy-like indexing\n",
    "print(y[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\ntorch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
    }
   ],
   "source": [
    "# Resize/reshape\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())\n",
    "\n",
    "# Numpy-like .reshape()\n",
    "y = x.reshape(16)\n",
    "z = x.reshape(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([0.8660])\n0.8660114407539368\n"
    }
   ],
   "source": [
    "# Get the only one element from tensor as Python-number\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1., 1., 1., 1., 1.])\n[1. 1. 1. 1. 1.]\ntensor([2., 2., 2., 2., 2.])\n[2. 2. 2. 2. 2.]\n"
    }
   ],
   "source": [
    "# Convert torch array to numpy array\n",
    "x = torch.ones(5)\n",
    "print(x)\n",
    "x_np = x.numpy()\n",
    "print(x_np)\n",
    "\n",
    "# The values are shared between torch-tensor and numpy-array\n",
    "x.add_(1)\n",
    "print(x)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[2. 2. 2. 2. 2.]\ntensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
    }
   ],
   "source": [
    "# Build torch array from numpy array, and share the values\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a) # it is different from a = a+1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "False\n"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch tensor indexing\n",
    "Test indexing and dimension of torch-tensor & variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor(1.), torch.Tensor, torch.Size([]))"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Indexing a scalar from torch-tensor would return a zero-dimensional torch-tensor\n",
    "x = torch.Tensor([1, 2, 3])\n",
    "x0 = x[0]\n",
    "x0, type(x0), x0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([1., 2.]), torch.Tensor, torch.Size([2]))"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Indexing a tensor from torch-tensor would return a torch-tensor\n",
    "x0 = x[:2]\n",
    "x0, type(x0), x0.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and Variables have merged\n",
    "torch.Tensor and torch.autograd.Variable are now the same class.  \n",
    "More precisely, torch.Tensor is capable of tracking history and behaves like the old Variable; Variable wrapping continues to work as before but returns an object of type torch.Tensor.  \n",
    "This means that you don’t need the Variable wrapper everywhere in your code anymore.  \n",
    "\n",
    "Variable.data was the primary way to get the underlying Tensor from a Variable. After this merge, calling y = x.data still has similar semantics. So y will be a Tensor that shares the same data with x, is unrelated with the computation history of x, and has requires_grad=False.  \n",
    "However, Variable.data can be unsafe in some cases. Any changes on x.data wouldn’t be tracked by autograd, and the computed gradients would be incorrect if x is needed in a backward pass. A safer alternative is to use x.detach(), which also returns a Tensor that shares data with requires_grad=False, but will have its in-place changes reported by autograd if x is needed in backward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor(1.), torch.Tensor, torch.Size([]))"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Indexing a scalar from torch-variable would return a 1-dimension variable (vector) \n",
    "# NOTE: torch-variable is at least 1-dimension, i.e., at least vector (Depreciated)\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x_var = Variable(x)\n",
    "x0 = x_var[0]\n",
    "x0, type(x0), x0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([1., 2.]), torch.Tensor, torch.Size([2]))"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Indexing a tensor from torch-variable would return a torch-variable\n",
    "x0 = x_var[:2]\n",
    "x0, type(x0), x0.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 1.],\n        [1., 1.]])\nFalse\ntensor([[1., 1.],\n        [1., 1.]], requires_grad=True)\nTrue\n"
    }
   ],
   "source": [
    "x = torch.ones(2, 2)\n",
    "print(x)\n",
    "print(x.requires_grad)\n",
    "\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[3., 3.],\n        [3., 3.]], grad_fn=<AddBackward0>)\nTrue\n<AddBackward0 object at 0x0000021D7D182208>\n"
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)\n",
    "print(y.requires_grad)\n",
    "# y was created as a result of an operation, so it has a grad_fn\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[27., 27.],\n        [27., 27.]], grad_fn=<MulBackward0>)\ntensor(27., grad_fn=<MeanBackward0>)\n"
    }
   ],
   "source": [
    "z = 3 * y ** 2\n",
    "out = z.mean()\n",
    "\n",
    "print(z)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "None\ntensor([[4.5000, 4.5000],\n        [4.5000, 4.5000]])\n"
    }
   ],
   "source": [
    "# NOTE: now x.grad is None\n",
    "print(x.grad)\n",
    "\n",
    "# Call backward function\n",
    "out.backward()\n",
    "\n",
    "# NOTE: now x.grad is not None, it is d(out)/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1.0000e+03, 1.0000e+04, 1.0000e+00])\n"
    }
   ],
   "source": [
    "# What if the output is NOT a scalar?\n",
    "x = torch.tensor([1, 2, 3], dtype=torch.float, requires_grad=True)\n",
    "out = x * 10000\n",
    "\n",
    "# NOTE: y is a vector (instead of a scalar), so torch.autograd could not compute the full Jacobian directly\n",
    "# But if we just want the vector-Jacobian product, simply pass the vector to backward as argument:\n",
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "out.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nTrue\nTrue\nFalse\n"
    }
   ],
   "source": [
    "# How to stop autograd from tracking history on Tensors?\n",
    "# Use torch.no_grad()\n",
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(x.requires_grad)\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1., 2., 3.], requires_grad=True)\ntensor([1., 2., 3.])\nFalse\n"
    }
   ],
   "source": [
    "# Use .detach() to get a new Tensor with the same content but that does not require gradients\n",
    "print(x)\n",
    "\n",
    "y = x.detach()\n",
    "print(y)\n",
    "print(y.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}