{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## size & dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.,   1.,   2.],\n",
       "         [  3.,   4.,   5.],\n",
       "         [  6.,   7.,   8.],\n",
       "         [  9.,  10.,  11.]],\n",
       "\n",
       "        [[ 12.,  13.,  14.],\n",
       "         [ 15.,  16.,  17.],\n",
       "         [ 18.,  19.,  20.],\n",
       "         [ 21.,  22.,  23.]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 24).view(2, 4, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 3]), 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(), x.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(0), x.size(1), x.size(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "print(x, x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.2000,  2.0000,  3.0000]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.2, 2, 3])\n",
    "print(x, x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## permute & transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.,   1.,   2.],\n",
       "         [  3.,   4.,   5.],\n",
       "         [  6.,   7.,   8.],\n",
       "         [  9.,  10.,  11.]],\n",
       "\n",
       "        [[ 12.,  13.,  14.],\n",
       "         [ 15.,  16.,  17.],\n",
       "         [ 18.,  19.,  20.],\n",
       "         [ 21.,  22.,  23.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 24).view(2, 4, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 3])\n",
      "torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "print(x.permute(2, 0, 1).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## squeeze & unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-0.8638,  1.5170]],\n",
      "\n",
      "          [[ 0.2666, -1.9463]]],\n",
      "\n",
      "\n",
      "         [[[-0.6103, -0.2184]],\n",
      "\n",
      "          [[-2.1175, -0.5560]]]]])\n",
      "tensor([[[-0.8638,  1.5170],\n",
      "         [ 0.2666, -1.9463]],\n",
      "\n",
      "        [[-0.6103, -0.2184],\n",
      "         [-2.1175, -0.5560]]])\n",
      "tensor([[[[-0.8638,  1.5170]],\n",
      "\n",
      "         [[ 0.2666, -1.9463]]],\n",
      "\n",
      "\n",
      "        [[[-0.6103, -0.2184]],\n",
      "\n",
      "         [[-2.1175, -0.5560]]]])\n",
      "tensor([[[[-0.8638,  1.5170],\n",
      "          [ 0.2666, -1.9463]],\n",
      "\n",
      "         [[-0.6103, -0.2184],\n",
      "          [-2.1175, -0.5560]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 2, 2, 1, 2)\n",
    "print(x)\n",
    "print(x.squeeze())\n",
    "print(x.squeeze(0))\n",
    "print(x.squeeze(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3]])\n",
      "tensor([[ 1,  2,  3]])\n",
      "tensor([[ 1],\n",
      "        [ 2],\n",
      "        [ 3]])\n",
      "tensor([[ 1],\n",
      "        [ 2],\n",
      "        [ 3]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "print(x.unsqueeze(0))\n",
    "print(x.view(1, -1))\n",
    "print(x.unsqueeze(1))\n",
    "print(x.view(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5668,  1.4982, -0.4502],\n",
      "        [ 1.8740,  0.3094, -1.2693],\n",
      "        [ 0.0587,  0.8242, -0.1666],\n",
      "        [ 1.0118,  0.4650, -1.1774],\n",
      "        [-1.6743,  0.3937, -1.7300],\n",
      "        [-0.9730, -0.3424, -0.6019]])\n",
      "tensor([[ 1.5668,  1.4982, -0.4502,  1.0118,  0.4650, -1.1774],\n",
      "        [ 1.8740,  0.3094, -1.2693, -1.6743,  0.3937, -1.7300],\n",
      "        [ 0.0587,  0.8242, -0.1666, -0.9730, -0.3424, -0.6019]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 3)\n",
    "y = torch.randn(3, 3)\n",
    "# dim=0 -> cat on column\n",
    "print(torch.cat([x, y], dim=0))\n",
    "# dim=1 -> cat on row\n",
    "print(torch.cat([x, y], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.5667955   1.4981884  -0.45018178]\n",
      " [ 1.8740447   0.30939355 -1.269309  ]\n",
      " [ 0.0587256   0.8242405  -0.16662787]\n",
      " [ 1.0117911   0.4649585  -1.177354  ]\n",
      " [-1.6743116   0.3937247  -1.7299552 ]\n",
      " [-0.97302073 -0.34240177 -0.60191107]]\n",
      "[[ 1.5667955   1.4981884  -0.45018178  1.0117911   0.4649585  -1.177354  ]\n",
      " [ 1.8740447   0.30939355 -1.269309   -1.6743116   0.3937247  -1.7299552 ]\n",
      " [ 0.0587256   0.8242405  -0.16662787 -0.97302073 -0.34240177 -0.60191107]]\n"
     ]
    }
   ],
   "source": [
    "# axis=0 -> cat on column\n",
    "print(np.concatenate([x.numpy(), y.numpy()], axis=0))\n",
    "# axis=1 -> cat on row\n",
    "print(np.concatenate([x.numpy(), y.numpy()], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate product of matrix and vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2,  3],\n",
       "         [ 3,  2,  1]]), tensor([[ 1],\n",
       "         [ 2],\n",
       "         [ 3]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], \n",
    "                  [3, 2, 1]])\n",
    "y = torch.tensor([[1], [2], [3]])\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 14],\n",
      "        [ 10]])\n",
      "tensor([[ 14],\n",
      "        [ 10]])\n"
     ]
    }
   ],
   "source": [
    "print(x @ y)\n",
    "print(torch.mm(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.dot is calculating inner product of vectors\n",
    "torch.dot(x[0], x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax\n",
    "$f_i(x) = \\frac{e^{x_i}}{\\sum_j{e^{x_j}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.]])\n",
      "tensor([[ 0.0900,  0.2447,  0.6652]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3]], dtype=torch.float32)\n",
    "print(x)\n",
    "# Specify dimension\n",
    "print(F.softmax(x, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  2.,  3.]])\n",
      "tensor([[ 0.3333,  0.3333,  0.3333],\n",
      "        [ 0.0900,  0.2447,  0.6652]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 1, 1], [1, 2, 3]], dtype=torch.float32)\n",
    "print(x)\n",
    "print(F.softmax(x, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  1.,  1.],\n",
      "         [ 1.,  2.,  3.]],\n",
      "\n",
      "        [[ 1.,  1.,  1.],\n",
      "         [ 3.,  2.,  1.]]])\n",
      "tensor([[[ 0.3333,  0.3333,  0.3333],\n",
      "         [ 0.0900,  0.2447,  0.6652]],\n",
      "\n",
      "        [[ 0.3333,  0.3333,  0.3333],\n",
      "         [ 0.6652,  0.2447,  0.0900]]])\n"
     ]
    }
   ],
   "source": [
    "# F.log_softmax cannot handle input over 3-rank, leading to wrong result (Depreciated)\n",
    "x = torch.tensor([[[1, 1, 1], [1, 2, 3]], \n",
    "                  [[1, 1, 1], [3, 2, 1]]], dtype=torch.float32)\n",
    "print(x)\n",
    "print(F.softmax(x, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  1.,  1.],\n",
      "         [ 1.,  2.,  3.]]])\n",
      "tensor([[[ 0.3333,  0.3333,  0.3333],\n",
      "         [ 0.0900,  0.2447,  0.6652]]])\n"
     ]
    }
   ],
   "source": [
    "print(x[:1])\n",
    "print(F.softmax(x[:1], dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log_softmax\n",
    "$f_i(x) = \\log{\\frac{e^{x_i}}{\\sum_j{e^{x_j}}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  3.])\n",
      "tensor([-2.4076, -1.4076, -0.4076])\n",
      "tensor([-2.4076, -1.4076, -0.4076])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "print(x)\n",
    "print(F.log_softmax(x, dim=-1))\n",
    "print(torch.log(F.softmax(x, dim=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigmoid\n",
    "$f(x) = \\frac{1}{1 + e^{-x}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  3.])\n",
      "tensor([ 0.7311,  0.8808,  0.9526])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "print(x)\n",
    "print(F.sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tanh\n",
    "$f(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  3.])\n",
      "tensor([ 0.7616,  0.9640,  0.9951])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "print(x)\n",
    "print(F.tanh(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU\n",
    "${ReLU}(x) = max(0, x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3., -2., -1.,  0.,  1.,  2.,  3.])\n",
      "tensor([ 0.,  0.,  0.,  0.,  1.,  2.,  3.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(-3, 4)\n",
    "print(x)\n",
    "print(F.relu(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.]), tensor([ 1.,  1.,  2.,  2.]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "y = torch.tensor([1, 1, 2, 2], dtype=torch.float32)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "loss_func(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set size_average=False, and get SSE loss\n",
    "loss_func = nn.MSELoss(size_average=False)\n",
    "loss_func(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smooth_L1_loss\n",
    "$$\n",
    "loss(x, y) = \n",
    "\\begin{cases}\n",
    "    0.5 * (x - y)^2, & \\text{if } |x - y| < 1 \\\\\n",
    "    |x - y| - 0.5,   & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "It is less sensitive to outliers than the `MSELoss` and in some cases  \n",
    "Also known as the Huber loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.]), tensor([ 1.,  1.,  2.,  2.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "y = torch.tensor([1, 1, 2, 2], dtype=torch.float32)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6250)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = nn.SmoothL1Loss()\n",
    "loss_func(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLLLoss: negative log likelihood  \n",
    "$$\n",
    "loss(x, class) = -x[class] \\\\\n",
    "\\text{where x is a vector of log likelihood of each class}\n",
    "$$\n",
    "\n",
    "The negative log likelihood loss. It is useful to train a classification\n",
    "problem with n classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.],\n",
       "         [ 3.,  3.]]), tensor([ 1,  0]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2], [3, 3]], dtype=torch.float32)\n",
    "y = torch.tensor([1, 0])\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3133, -0.3133],\n",
       "        [-0.6931, -0.6931]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use log_softmax to calculate log_likelihood \n",
    "x = F.log_softmax(x, dim=-1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5032)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = nn.NLLLoss()\n",
    "loss_func(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross entropy loss\n",
    "$$\n",
    "\\begin{split}\n",
    "loss(x, class) & = -log(\\frac{e^{x[class]}}{\\sum_j e^{x[j]}}) \\\\\n",
    "               & = -x[class] + log(\\sum_j e^{x[j]})\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.],\n",
       "         [ 3.,  3.]]), tensor([ 1,  0]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2], [3, 3]], dtype=torch.float32)\n",
    "y = torch.tensor([1, 0])\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5032)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "# NO need to calculate log_likelihood \n",
    "# get the same result with log_softmax -> NLLLoss\n",
    "loss_func(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD\n",
    "Args:  \n",
    "params (iterable): iterable of parameters to optimize or dicts defining parameter groups  \n",
    "lr (float): learning rate  \n",
    "momentum (float, optional): momentum factor (default: 0)  \n",
    "weight_decay (float, optional): weight decay (L2 penalty) (default: 0)  \n",
    "dampening (float, optional): dampening for momentum (default: 0)  \n",
    "nesterov (bool, optional): enables Nesterov momentum (default: False)  \n",
    "\n",
    "## Adadelta\n",
    "Arguments:  \n",
    "params (iterable): iterable of parameters to optimize or dicts defining parameter groups  \n",
    "rho (float, optional): coefficient used for computing a running average of squared gradients (default: 0.9)  \n",
    "eps (float, optional): term added to the denominator to improve numerical stability (default: 1e-6)  \n",
    "lr (float, optional): coefficient that scale delta before it is applied to the parameters (default: 1.0)  \n",
    "weight_decay (float, optional): weight decay (L2 penalty) (default: 0)  \n",
    "\n",
    "## Adam\n",
    "Arguments:\n",
    "params (iterable): iterable of parameters to optimize or dicts defining parameter groups  \n",
    "lr (float, optional): learning rate (default: 1e-3)  \n",
    "betas (Tuple[float, float], optional): coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))  \n",
    "eps (float, optional): term added to the denominator to improve numerical stability (default: 1e-8)  \n",
    "weight_decay (float, optional): weight decay (L2 penalty) (default: 0)  \n",
    "\n",
    "## L-BFGS\n",
    "Arguments:\n",
    "lr (float): learning rate (default: 1)  \n",
    "max_iter (int): maximal number of iterations per optimization step (default: 20)  \n",
    "max_eval (int): maximal number of function evaluations per optimization step (default: max_iter * 1.25).  \n",
    "tolerance_grad (float): termination tolerance on first order optimality (default: 1e-5).  \n",
    "tolerance_change (float): termination tolerance on function value/parameter changes (default: 1e-9).  \n",
    "history_size (int): update history size (default: 100).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97211564, 1.0640465 , 1.052424  , 1.0333021 , 1.0172589 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "M = 500\n",
    "N = 5\n",
    "\n",
    "x = np.random.randn(M, N).astype(np.float32)\n",
    "y = x.sum(axis=1) + np.random.randn(M).astype(np.float32)\n",
    "\n",
    "ols = linear_model.LinearRegression()\n",
    "ols.fit(x, y)\n",
    "ols.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([500, 5]), torch.Size([500]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "x = torch.from_numpy(x).cuda()\n",
    "y = torch.from_numpy(y).cuda()\n",
    "x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.9721,  1.0640,  1.0524,  1.0333,  1.0173]], device='cuda:0'), Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [-4.2673], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "# test for SGD\n",
    "# network\n",
    "fc = nn.Linear(5, 1)\n",
    "fc.cuda()\n",
    "\n",
    "# loss function\n",
    "loss_func = nn.MSELoss(size_average=True)\n",
    "optimizer = optim.SGD(fc.parameters(), lr=0.01)\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = fc(x)\n",
    "    # MUST put the predicted varibale at the first argument\n",
    "    loss = loss_func(y_pred, y.view(-1, 1))\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "for epoch in range(10000):\n",
    "    optimizer.step(closure=closure)\n",
    "print(list(fc.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.9721,  1.0640,  1.0524,  1.0333,  1.0173]], device='cuda:0'),\n",
       " Parameter containing:\n",
       " tensor(1.00000e-02 *\n",
       "        [-4.2671], device='cuda:0')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for L-BFGS\n",
    "# network\n",
    "fc = nn.Linear(5, 1)\n",
    "fc.cuda()\n",
    "\n",
    "# loss function\n",
    "loss_func = nn.MSELoss(size_average=True)\n",
    "optimizer = optim.LBFGS(fc.parameters())\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = fc(x)\n",
    "    # MUST put the predicted varibale at the first argument\n",
    "    loss = loss_func(y_pred, y.view(-1, 1))\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "# Performs a single optimization step\n",
    "optimizer.step(closure=closure)\n",
    "\n",
    "list(fc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.9721,  1.0640,  1.0524,  1.0333,  1.0173]], device='cuda:0'), Parameter containing:\n",
      "tensor(1.00000e-02 *\n",
      "       [-4.2673], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "# test for Adam\n",
    "# network\n",
    "fc = nn.Linear(5, 1)\n",
    "fc.cuda()\n",
    "\n",
    "# loss function\n",
    "loss_func = nn.MSELoss(size_average=True)\n",
    "\n",
    "optimizer = optim.Adam(fc.parameters())\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = fc(x)\n",
    "    # MUST put the predicted varibale at the first argument\n",
    "    loss = loss_func(y_pred, y.view(-1, 1))\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "for epoch in range(10000):\n",
    "    optimizer.step(closure=closure)\n",
    "print(list(fc.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  0.,   2.,   0.,   0.,   0.,  10.,   0.,  14.,  16.,   0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 10)\n",
    "print(x)\n",
    "\n",
    "dropout_layer = nn.Dropout(0.5)\n",
    "dropout_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.0000,   1.2500,   2.5000,   3.7500,   5.0000,   6.2500,\n",
       "          7.5000,   8.7500,  10.0000,  11.2500])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_layer = nn.Dropout(0.2)\n",
    "dropout_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_layer.eval()\n",
    "print(dropout_layer.training)\n",
    "dropout_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  0.0000,   1.2500,   0.0000,   3.7500,   5.0000,   6.2500,\n",
       "          7.5000,   0.0000,  10.0000,   0.0000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_layer.train()\n",
    "print(dropout_layer.training)\n",
    "dropout_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
