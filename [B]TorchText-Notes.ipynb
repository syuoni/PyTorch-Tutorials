{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "SEED = 515\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data import Field, LabelField, BucketIterator\n",
    "\n",
    "# Set `batch_first=True` in the `Field`.\n",
    "TEXT = Field(tokenize='spacy', include_lengths=True, batch_first=True)\n",
    "LABEL = LabelField()\n",
    "\n",
    "train_data, test_data = torchtext.datasets.TREC.splits(TEXT, LABEL, fine_grained=False, root='data')\n",
    "train_data, valid_data = train_data.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "defaultdict(None, {'ENTY': 0, 'HUM': 1, 'DESC': 2, 'NUM': 3, 'LOC': 4, 'ABBR': 5})\n"
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE, \n",
    "                 vectors=\"glove.6B.100d\", vectors_cache=\"vector_cache\", \n",
    "                 unk_init=torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['What', 'do', 'the', 'letters', 'D.C.', 'stand', 'for', 'in', 'Washington', ',', 'D.C.', '?']\ntensor([[  4,  24,   3, 297, 552, 106,  18,   7, 286,  14, 552,   2]])\ntensor([12])\n"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "ex = train_data[0]\n",
    "print(ex.text)\n",
    "# If `include_lengths=False`, it should be:  \n",
    "# `TEXT.numericalize([ex.text], device=device)`\n",
    "text, text_lens = TEXT.numericalize(([ex.text], [len(ex.text)]), device=device)\n",
    "print(text)\n",
    "print(text_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE, sort_within_batch=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `BucketIterator.splits`\n",
    "By default, the first dataset (`train_iterator`) would be shuffled, while the other datasets (`valid_iterator` and `test_iterator`) would be not shuffled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(11) tensor(11) tensor(11)\ntensor(16) tensor(16) tensor(15)\ntensor(6) tensor(6) tensor(5)\ntensor(9) tensor(9) tensor(9)\ntensor(20) tensor(20) tensor(17)\ntensor(11) tensor(11) tensor(11)\ntensor(10) tensor(10) tensor(10)\ntensor(15) tensor(15) tensor(14)\ntensor(10) tensor(10) tensor(10)\ntensor(14) tensor(14) tensor(13)\n"
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "    text, text_lens = batch.text\n",
    "    print(text_lens.max(), text_lens[0], text_lens[-1])\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(14) tensor(14) tensor(13)\ntensor(7) tensor(7) tensor(6)\ntensor(7) tensor(7) tensor(7)\ntensor(11) tensor(11) tensor(10)\ntensor(11) tensor(11) tensor(11)\ntensor(6) tensor(6) tensor(5)\ntensor(16) tensor(16) tensor(15)\ntensor(9) tensor(9) tensor(9)\ntensor(10) tensor(10) tensor(9)\ntensor(12) tensor(12) tensor(12)\n"
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "    text, text_lens = batch.text\n",
    "    print(text_lens.max(), text_lens[0], text_lens[-1])\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(5) tensor(5) tensor(3)\ntensor(7) tensor(7) tensor(6)\ntensor(7) tensor(7) tensor(7)\ntensor(8) tensor(8) tensor(7)\ntensor(9) tensor(9) tensor(8)\ntensor(9) tensor(9) tensor(9)\ntensor(10) tensor(10) tensor(9)\ntensor(11) tensor(11) tensor(10)\ntensor(12) tensor(12) tensor(11)\ntensor(13) tensor(13) tensor(12)\n"
    }
   ],
   "source": [
    "for i, batch in enumerate(valid_iterator):\n",
    "    text, text_lens = batch.text\n",
    "    print(text_lens.max(), text_lens[0], text_lens[-1])\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(5) tensor(5) tensor(3)\ntensor(7) tensor(7) tensor(6)\ntensor(7) tensor(7) tensor(7)\ntensor(8) tensor(8) tensor(7)\ntensor(9) tensor(9) tensor(8)\ntensor(9) tensor(9) tensor(9)\ntensor(10) tensor(10) tensor(9)\ntensor(11) tensor(11) tensor(10)\ntensor(12) tensor(12) tensor(11)\ntensor(13) tensor(13) tensor(12)\n"
    }
   ],
   "source": [
    "for i, batch in enumerate(valid_iterator):\n",
    "    text, text_lens = batch.text\n",
    "    print(text_lens.max(), text_lens[0], text_lens[-1])\n",
    "    if i >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}