{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Pretrained Transformers for PoS Tagging\n",
    "\n",
    "A BERT followed by a linear layer for Part-of-Speech (PoS) Tagging.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "SEED = 515\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "30522\n"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# tokenizer.save_pretrained('./transformers_cache/bert-base-uncased/')\n",
    "tokenizer = BertTokenizer.from_pretrained('./transformers_cache/bert-base-uncased/')\n",
    "print(len(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['hello', 'world', 'how', 'are', 'you', '?']\n[7592, 2088, 2129, 2024, 2017, 1029]\n[101, 7592, 2088, 2129, 2024, 2017, 1029, 102]\n"
    }
   ],
   "source": [
    "# This will tokenize and lower case the data in a way that is consistent with the pre-trained transformer model.\n",
    "text = \"Hello WORLD how ARE yoU?\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)\n",
    "\n",
    "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(indexes)\n",
    "\n",
    "indexes = tokenizer.encode(text, add_special_tokens=True)\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[CLS] [SEP] [PAD] [UNK]\n"
    }
   ],
   "source": [
    "# `cls_token`: The classifier token which is used when doing sequence classification (classification of the whole\n",
    "# sequence instead of per-token classification). It is the first token of the sequence when built with special tokens.\n",
    "init_token = tokenizer.cls_token\n",
    "# `sep_token`: The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences\n",
    "# for sequence classification or for a text and a question for question answering. It is also used as the last token of \n",
    "# a sequence built with special tokens.\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "101 102 0 100\n"
    }
   ],
   "source": [
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "512\n"
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "print(max_input_length)\n",
    "\n",
    "def cut_and_convert_to_ids(tokens, tokenizer, max_len):\n",
    "    # Add special `[CLS]` and `[SEP]` tokens to the start and end of the tokens\n",
    "    return tokenizer.convert_tokens_to_ids(tokens[:max_len-2])\n",
    "\n",
    "def cut_to_max_len(tags, max_len):\n",
    "    # Add special `[CLS]` and `[SEP]` tokens to the start and end of the tokens\n",
    "    return tags[:max_len-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "# Use `functools.partial` to pass functions with some of their arguments supplied\n",
    "text_preprocessor = functools.partial(cut_and_convert_to_ids, tokenizer=tokenizer, max_len=max_input_length)\n",
    "tag_preprocessor = functools.partial(cut_to_max_len, max_len=max_input_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "\n",
    "The dataset is Universal Dependencies English Web Treebank (UDPOS).  \n",
    "This dataset actually has two different sets of tags, [universal dependency (UD) tags](https://universaldependencies.org/u/pos/) and [Penn Treebank (PTB) tags](https://www.sketchengine.eu/penn-treebank-tagset/).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "# The data for PoS Tagging have already been tokenized, so NO need for a tokenizer\n",
    "# `use_vocab`: Whether to use a Vocab object. If False, the data in this field should already be numerical.\n",
    "TEXT = Field(batch_first=True, use_vocab=False, lower=True, preprocessing=text_preprocessor, \n",
    "             init_token=init_token_idx, eos_token=eos_token_idx, pad_token=pad_token_idx, unk_token=unk_token_idx,\n",
    "             include_lengths=True)\n",
    "\n",
    "# Because the set of possible tags is finite, do NOT use unknown token for it. \n",
    "# Add `<pad>` to both the start and end of tags, consistent to which has been done to the tokens. \n",
    "# Note the `<pad>` token will be ignored when calculating loss and accuracy. \n",
    "UD_TAGS = Field(batch_first=True, preprocessing=tag_preprocessor, \n",
    "                init_token='<pad>', eos_token='<pad>', unk_token=None, include_lengths=True)\n",
    "PTB_TAGS = Field(batch_first=True, preprocessing=tag_preprocessor, \n",
    "                 init_token='<pad>', eos_token='<pad>', unk_token=None, include_lengths=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import UDPOS\n",
    "\n",
    "fields = [('text', TEXT), ('udtags', UD_TAGS), ('ptbtags', PTB_TAGS)]\n",
    "train_data, valid_data, test_data = UDPOS.splits(fields=fields, root='data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[2632, 1011, 100, 1024, 2137, 2749, 2730, 100, 14093, 2632, 1011, 100, 1010, 1996, 14512, 2012, 1996, 8806, 1999, 1996, 2237, 1997, 100, 1010, 2379, 1996, 9042, 3675, 1012]\n['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']\n"
    }
   ],
   "source": [
    "print(train_data[0].text)\n",
    "print(train_data[0].udtags)\n",
    "print(train_data[0].ptbtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "18 51\n['<pad>', 'NOUN', 'PUNCT', 'VERB', 'PRON', 'ADP', 'DET', 'PROPN', 'ADJ', 'AUX', 'ADV', 'CCONJ', 'PART', 'NUM', 'SCONJ', 'X', 'INTJ', 'SYM']\n"
    }
   ],
   "source": [
    "UD_TAGS.build_vocab(train_data)\n",
    "PTB_TAGS.build_vocab(train_data)\n",
    "\n",
    "print(len(UD_TAGS.vocab), len(PTB_TAGS.vocab))\n",
    "print(UD_TAGS.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[  101,  2004,  2017,  2113,  1010,  2256,  2279,  3116,  2003,  2006,\n          9317,  1010,  2251,  2260,  2013,   100,  1011,   100,   100,  1012,\n           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101,  2028,  2518,  2008,  2515,   100,  2265,  2039,  1999,  1996,\n         14449,  2003,  1996, 19948, 11395,  3277,  1012,   102,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101,  2190,  1010,   102,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101, 11781,  5785,  1998,  1045,  2052,  2066,  2000,  3113,  2007,\n          2017,  2000,  6848,  1996,  3314,  7175,   100,  2077,  2057, 10838,\n          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101,  1996,   100,  2763,  2003, 13856,  2008,  2002,  2003,  1997,\n          2593,  6811,  5499, 24815,  1010,  6811,  5499,  2177,  2030, 24815,\n          1011,  2632, 18659,  1010,  2029,  2003,  2941,  1996,  2440,  2171,\n          1997,  1996,  2177,  2044,  1996,  7660,  1997,  1996,  6811,  5499,\n         24815,  1998,  2632, 18659,  1012,   102],\n        [  101,  4773,  6866,  2012,  1024,   100,   100,  9765,  1006,   100,\n           100,  1007,   102,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101,   100,  2133,  1045,  2572,  5220,  2007,  1996,  3007, 26192,\n          1010, 23724,  3539,  1010,  1996,  5340,  1010,  1996,  3539, 19395,\n          1010, 11164,  1055,  1010,  7920,  3782,  1005,  1010,  4385,  1012,\n           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101,  2009,  3504,  2066,  1996,  1016,  1011,  2154,   100,  3277,\n          2003,  2019,  3277,  1012,   102,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]], device='cuda:0')\ntensor([21, 18,  4, 22, 46, 13, 31, 15], device='cuda:0')\ntensor([[ 0, 14,  4,  3,  2,  4,  8,  1,  9,  5,  7,  2,  7, 13,  5, 13, 17, 13,\n          1,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n        [ 0, 13,  1,  4,  9, 12,  3,  5,  5,  6,  1,  9,  6,  1,  1,  1,  2,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n        [ 0,  8,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n        [ 0,  7,  7, 11,  4,  9,  3, 12,  3,  5,  4, 12,  3,  6,  1,  3,  7, 14,\n          4,  3,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n        [ 0,  6,  1, 10,  9,  3, 14,  4,  9,  5, 11,  8,  7,  7,  2,  8,  7,  7,\n         11,  7,  2,  7,  7,  2,  4,  9, 10,  6,  8,  1,  5,  6,  1,  5,  6,  1,\n          5,  6,  8,  7,  7, 11,  7,  7,  2,  0],\n        [ 0,  1,  3,  5,  2, 13,  1,  7,  2, 13,  7,  2,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n        [ 0,  1,  2,  4,  9,  8,  5,  6,  7,  7,  2,  7,  7,  2,  6,  7,  2,  6,\n          7,  7,  2,  7, 12,  2,  7,  7, 12,  2, 15,  2,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n        [ 0,  4,  3, 14,  6, 13,  2,  1,  1,  1,  9,  6,  1,  2,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0]], device='cuda:0')\ntensor([21, 18,  4, 22, 46, 13, 31, 15], device='cuda:0')\ntensor([True, True, True, True, True, True, True, True], device='cuda:0')\n"
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    batch_text, batch_text_lens = batch.text\n",
    "    batch_tags, batch_tags_lens = batch.udtags\n",
    "    break\n",
    "\n",
    "print(batch_text)\n",
    "print(batch_text_lens)\n",
    "print(batch_tags)\n",
    "print(batch_tags_lens)\n",
    "\n",
    "print(batch_text_lens == batch_tags_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "`BertModel.forward`\n",
    "* Input\n",
    "    * `input_ids`: (batch, step)\n",
    "    * `attention_mask`: (batch, step)\n",
    "        * Mask to avoid performing attention on padding token indices  \n",
    "        * A `torch.FloatTensor` with values selected in `{0, 1}`; The value being `0` means `masked`, and the value being `1` means `not-masked` \n",
    "* Output\n",
    "    * `last_hidden_state`: (batch, step, hidden)\n",
    "        * Sequence of hidden-states at the output of the last layer of the model  \n",
    "    * `pooler_output`: (batch, hidden)\n",
    "        * Last layer hidden-state of the first token of the sequence (classification token)\n",
    "        * It will be further processed by a linear layer and a `tanh`, which was trained for next sentence prediction (classification) objective  \n",
    "    * `attentions`: tuple of (batch, head, step, step), returned when `config.output_attentions=True`  \n",
    "        * Attention weights after the `softmax`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "# bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "# bert.save_pretrained('./transformers_cache/bert-base-uncased/')\n",
    "\n",
    "# Set `output_attentions=True` to return attentions from `bert.forward`\n",
    "bert = BertModel.from_pretrained('./transformers_cache/bert-base-uncased/', output_attentions=True).to(device)\n",
    "bert.config.output_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([8, 46])\ntorch.Size([8, 46, 768])\ntorch.Size([8, 768])\n12 12\ntorch.Size([8, 12, 46, 46])\n"
    }
   ],
   "source": [
    "# mask: (batch, step)\n",
    "mask = (batch.text[0] != pad_token_idx).float()\n",
    "bert_outs, bert_pooled_outs, attens = bert(batch.text[0], attention_mask=mask)\n",
    "print(batch.text[0].size())\n",
    "print(bert_outs.size())\n",
    "print(bert_pooled_outs.size())\n",
    "\n",
    "print(len(attens), bert.config.num_hidden_layers)\n",
    "print(attens[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(2.3842e-07, device='cuda:0', grad_fn=<MaxBackward1>)\ntensor(True, device='cuda:0')\ntensor([[[0.0371, 0.0607, 0.0216,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0758, 0.0309, 0.0481,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0611, 0.0352, 0.0358,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0066, 0.0118, 0.0788,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0064, 0.0104, 0.0833,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0068, 0.0114, 0.0812,  ..., 0.0000, 0.0000, 0.0000]],\n\n        [[0.0360, 0.0951, 0.0281,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0832, 0.0308, 0.0522,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0587, 0.0141, 0.0430,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0076, 0.0175, 0.0849,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0074, 0.0183, 0.0868,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0079, 0.0183, 0.0854,  ..., 0.0000, 0.0000, 0.0000]],\n\n        [[0.1473, 0.0975, 0.1198,  ..., 0.0000, 0.0000, 0.0000],\n         [0.2599, 0.0979, 0.3725,  ..., 0.0000, 0.0000, 0.0000],\n         [0.2409, 0.2582, 0.2070,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0807, 0.4920, 0.1497,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0769, 0.5281, 0.1259,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0799, 0.5077, 0.1497,  ..., 0.0000, 0.0000, 0.0000]],\n\n        ...,\n\n        [[0.0596, 0.0475, 0.0538,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0296, 0.0625, 0.1608,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0197, 0.0500, 0.0456,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0079, 0.1442, 0.1623,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0076, 0.1425, 0.1662,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0083, 0.1516, 0.1691,  ..., 0.0000, 0.0000, 0.0000]],\n\n        [[0.0265, 0.0166, 0.0273,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0173, 0.0232, 0.0245,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0282, 0.0090, 0.0298,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0039, 0.0542, 0.0395,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0039, 0.0571, 0.0384,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0041, 0.0527, 0.0399,  ..., 0.0000, 0.0000, 0.0000]],\n\n        [[0.0405, 0.0608, 0.0184,  ..., 0.0000, 0.0000, 0.0000],\n         [0.1032, 0.0334, 0.0586,  ..., 0.0000, 0.0000, 0.0000],\n         [0.1082, 0.0448, 0.0666,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0110, 0.0325, 0.2019,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0107, 0.0322, 0.2157,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0114, 0.0330, 0.2016,  ..., 0.0000, 0.0000, 0.0000]]],\n       device='cuda:0', grad_fn=<SelectBackward>)\n"
    }
   ],
   "source": [
    "# Check whether the attention is 0 on padding positions \n",
    "print((attens[0].sum(dim=-1) - 1).abs().max())\n",
    "print(((attens[0] != 0) == mask.view(mask.size(0), 1, 1, -1)).all())\n",
    "\n",
    "# Show the first head attention\n",
    "print(attens[0][:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[  101,  2004,  2017,  2113,  1010,  2256,  2279,  3116,  2003,  2006,\n          9317,  1010,  2251,  2260,  2013,   100,  1011,   100,   100,  1012,\n           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101,  2028,  2518,  2008,  2515,   100,  2265,  2039,  1999,  1996,\n         14449,  2003,  1996, 19948, 11395,  3277,  1012,   102,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101,  2190,  1010,   102,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101, 11781,  5785,  1998,  1045,  2052,  2066,  2000,  3113,  2007,\n          2017,  2000,  6848,  1996,  3314,  7175,   100,  2077,  2057, 10838,\n          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101,  1996,   100,  2763,  2003, 13856,  2008,  2002,  2003,  1997,\n          2593,  6811,  5499, 24815,  1010,  6811,  5499,  2177,  2030, 24815,\n          1011,  2632, 18659,  1010,  2029,  2003,  2941,  1996,  2440,  2171,\n          1997,  1996,  2177,  2044,  1996,  7660,  1997,  1996,  6811,  5499,\n         24815,  1998,  2632, 18659,  1012,   102],\n        [  101,  4773,  6866,  2012,  1024,   100,   100,  9765,  1006,   100,\n           100,  1007,   102,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101,   100,  2133,  1045,  2572,  5220,  2007,  1996,  3007, 26192,\n          1010, 23724,  3539,  1010,  1996,  5340,  1010,  1996,  3539, 19395,\n          1010, 11164,  1055,  1010,  7920,  3782,  1005,  1010,  4385,  1012,\n           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0],\n        [  101,  2009,  3504,  2066,  1996,  1016,  1011,  2154,   100,  3277,\n          2003,  2019,  3277,  1012,   102,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0]], device='cuda:0')\ntensor([[[ 0.0769, -0.0570,  0.2451,  ..., -0.2046,  0.6273,  0.4673],\n         [ 0.4734,  0.3849,  0.9369,  ..., -0.3964,  0.8343, -0.1047],\n         [-0.2909, -0.4783,  0.4526,  ...,  0.0791,  1.0221, -0.1757],\n         ...,\n         [ 0.7305, -0.1491,  0.4485,  ..., -0.1232,  0.7921, -0.5128],\n         [ 0.6838, -0.0735,  0.3398,  ...,  0.1665,  0.6859, -0.4842],\n         [ 0.6556,  0.0072,  0.3907,  ...,  0.0989,  0.7999, -0.2351]],\n\n        [[-0.1209,  0.1067, -0.0999,  ..., -0.1584,  0.2379,  0.7386],\n         [-0.0933, -0.6518, -0.5936,  ...,  0.4867,  0.4932,  0.4381],\n         [-0.2321,  0.2492, -0.4463,  ...,  0.5528,  0.3573,  0.1935],\n         ...,\n         [ 0.1250, -0.3197,  0.3454,  ...,  0.1639, -0.0670,  0.2528],\n         [ 0.2092, -0.2000,  0.3812,  ...,  0.2472, -0.0504,  0.2701],\n         [ 0.4238, -0.0508,  0.3934,  ...,  0.3031, -0.0260,  0.2671]],\n\n        [[-0.3413, -0.1676,  0.0666,  ..., -0.0840,  0.6023,  0.2980],\n         [-0.9700, -0.0442,  0.3747,  ..., -0.0295,  0.4770, -0.7113],\n         [-0.4982, -0.4454, -0.0086,  ...,  0.2332,  0.3803, -0.0201],\n         ...,\n         [-0.5190, -0.7377, -0.0875,  ...,  0.4154,  0.4091, -0.2733],\n         [-0.5643, -0.3510,  0.3562,  ...,  0.1060,  0.0471, -0.2437],\n         [-0.5669, -0.3766,  0.3298,  ...,  0.1417,  0.0691, -0.2688]],\n\n        ...,\n\n        [[-0.1916,  0.0775, -0.1557,  ..., -0.4283,  0.3999,  0.3517],\n         [ 0.4883, -0.1084,  0.2972,  ..., -0.0376,  1.2820, -0.0818],\n         [ 0.7534, -0.4923,  0.2440,  ..., -0.3885,  0.0250,  0.1736],\n         ...,\n         [ 0.7305, -0.2917, -0.1203,  ..., -0.5357,  0.5634, -0.8071],\n         [ 0.9367, -0.3750, -0.1660,  ..., -0.4826,  0.6776, -0.8912],\n         [ 0.9415, -0.4005, -0.2510,  ..., -0.4339,  0.7756, -0.8697]],\n\n        [[-0.0523,  0.4559, -0.1427,  ..., -0.0355,  0.4534,  0.7516],\n         [ 0.6562,  0.4416,  0.4015,  ..., -0.1177,  0.3451,  0.1496],\n         [ 0.4429,  0.2421,  0.4153,  ...,  0.0203,  0.2480, -0.6065],\n         ...,\n         [ 0.0079,  0.4130,  0.3516,  ...,  0.0860,  0.0549, -0.1249],\n         [ 0.0145,  0.1884,  0.1995,  ...,  0.1043,  0.2565, -0.1726],\n         [ 0.0847,  0.1485,  0.2978,  ...,  0.1363,  0.2471, -0.2497]],\n\n        [[ 0.0861,  0.1544,  0.3120,  ..., -0.2535,  0.4442,  0.3109],\n         [ 0.1326, -0.3871, -0.1776,  ..., -0.1282,  1.0255,  0.0487],\n         [ 0.1952, -0.0647,  0.5402,  ..., -0.2663,  0.6125, -0.1375],\n         ...,\n         [-0.3188, -0.7590,  0.1577,  ...,  0.6740,  0.4053, -0.2384],\n         [-0.0067, -0.1792,  0.5996,  ...,  0.2164,  0.2336, -0.1786],\n         [-0.1205, -0.2219,  0.4211,  ...,  0.2431,  0.3041,  0.0965]]],\n       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n"
    }
   ],
   "source": [
    "# The values at padding positions are NOT zeros? \n",
    "# Yes, but they will never pollute the non-padding positions, since the attentions are applied with masking. \n",
    "print(batch.text[0])\n",
    "print(bert_outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using an embedding layer to get embeddings for our text, we'll be using the pre-trained transformer model. These embeddings will then be fed into a linear layer to predict the tag for each token.  \n",
    "\n",
    "We get the embedding dimension size (called the `hidden_size`) from the transformer via its config attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoSTagger(nn.Module):\n",
    "    def __init__(self, bert, tag_dim, dropout):\n",
    "        super().__init__()\n",
    "        # Use `bert` to provide word embeddings. \n",
    "        self.bert = bert\n",
    "        emb_dim = bert.config.hidden_size\n",
    "        \n",
    "        self.fc = nn.Linear(emb_dim, tag_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text/mask: (batch, step)\n",
    "        mask = (text != self.bert.config.pad_token_id).float()\n",
    "        embedded, *_ = self.bert(text, attention_mask=mask)\n",
    "\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # preds: (batch, step, tag_dim)\n",
    "        preds = self.fc(embedded)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([8, 46])\ntorch.Size([8, 46, 18])\n"
    }
   ],
   "source": [
    "TAG_DIM = len(UD_TAGS.vocab)\n",
    "# TAG_DIM = len(PTB_TAGS.vocab)\n",
    "\n",
    "DROPOUT = 0.25\n",
    "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
    "# TAG_PAD_IDX = PTB_TAGS.vocab.stoi[PTB_TAGS.pad_token]\n",
    "\n",
    "\n",
    "tagger = PoSTagger(bert, TAG_DIM, DROPOUT).to(device)\n",
    "preds = tagger(batch_text)\n",
    "\n",
    "print(batch_text.size())\n",
    "print(preds.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(0., device='cuda:0', grad_fn=<MaxBackward1>)"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Check if data are mixed across different samples in a batch.\n",
    "tagger.eval()\n",
    "preds_012 = tagger(batch_text[0:3, :])\n",
    "preds_123 = tagger(batch_text[1:4, :])\n",
    "\n",
    "(preds_012[1:] - preds_123[:2]).abs().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The model has 109,496,082 trainable parameters\n"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Count trainable parameters. \n",
    "    \"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(tagger):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "optimizer = optim.AdamW(tagger.parameters(), lr=LEARNING_RATE)\n",
    "loss_func = nn.CrossEntropyLoss(ignore_index=TAG_PAD_IDX, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(tagger, iterator, optimizer, loss_func):\n",
    "    tagger.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for batch in iterator:\n",
    "        # Forward pass\n",
    "        text, text_lens = batch.text\n",
    "        tags, tags_lens = batch.udtags\n",
    "        preds = tagger(text)\n",
    "\n",
    "        # Calculate loss\n",
    "        preds_flattened = preds.view(-1, preds.size(-1))\n",
    "        tags_flattened = tags.flatten()\n",
    "        loss = loss_func(preds_flattened, tags_flattened)\n",
    "\n",
    "        # Backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Accumulate loss and acc\n",
    "        epoch_loss += loss.item()\n",
    "        non_padding = (tags_flattened != loss_func.ignore_index)\n",
    "        epoch_acc += (preds_flattened.argmax(dim=-1) == tags_flattened)[non_padding].sum().item() / non_padding.sum().item()\n",
    "    return epoch_loss/len(iterator), epoch_acc/len(iterator)\n",
    "\n",
    "def eval_epoch(tagger, iterator, loss_func):\n",
    "    tagger.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            # Forward pass\n",
    "            text, text_lens = batch.text\n",
    "            tags, tags_lens = batch.udtags\n",
    "            preds = tagger(text)\n",
    "\n",
    "            # Calculate loss\n",
    "            preds_flattened = preds.view(-1, preds.size(-1))\n",
    "            tags_flattened = tags.flatten()\n",
    "            loss = loss_func(preds_flattened, tags_flattened)\n",
    "            \n",
    "            # Accumulate loss and acc\n",
    "            epoch_loss += loss.item()\n",
    "            non_padding = (tags_flattened != loss_func.ignore_index)\n",
    "            epoch_acc += (preds_flattened.argmax(dim=-1) == tags_flattened)[non_padding].sum().item() / non_padding.sum().item()\n",
    "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch: 01 | Epoch Time: 6m 18s\n\tTrain Loss: 0.220 | Train Acc: 93.74%\n\t Val. Loss: 0.254 |  Val. Acc: 91.84%\nEpoch: 02 | Epoch Time: 6m 17s\n\tTrain Loss: 0.092 | Train Acc: 97.24%\n\t Val. Loss: 0.237 |  Val. Acc: 92.88%\nEpoch: 03 | Epoch Time: 6m 17s\n\tTrain Loss: 0.060 | Train Acc: 98.21%\n\t Val. Loss: 0.249 |  Val. Acc: 93.16%\nEpoch: 04 | Epoch Time: 6m 9s\n\tTrain Loss: 0.042 | Train Acc: 98.68%\n\t Val. Loss: 0.275 |  Val. Acc: 92.97%\nEpoch: 05 | Epoch Time: 6m 11s\n\tTrain Loss: 0.033 | Train Acc: 98.96%\n\t Val. Loss: 0.294 |  Val. Acc: 92.39%\nEpoch: 06 | Epoch Time: 6m 24s\n\tTrain Loss: 0.027 | Train Acc: 99.20%\n\t Val. Loss: 0.305 |  Val. Acc: 92.26%\nEpoch: 07 | Epoch Time: 6m 24s\n\tTrain Loss: 0.021 | Train Acc: 99.34%\n\t Val. Loss: 0.330 |  Val. Acc: 92.82%\nEpoch: 08 | Epoch Time: 6m 24s\n\tTrain Loss: 0.023 | Train Acc: 99.32%\n\t Val. Loss: 0.353 |  Val. Acc: 92.65%\nEpoch: 09 | Epoch Time: 6m 24s\n\tTrain Loss: 0.023 | Train Acc: 99.33%\n\t Val. Loss: 0.350 |  Val. Acc: 92.37%\nEpoch: 10 | Epoch Time: 6m 24s\n\tTrain Loss: 0.016 | Train Acc: 99.48%\n\t Val. Loss: 0.339 |  Val. Acc: 92.61%\n"
    }
   ],
   "source": [
    "import time\n",
    "N_EPOCHS = 10\n",
    "best_valid_loss = np.inf\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    t0 = time.time()\n",
    "    train_loss, train_acc = train_epoch(tagger, train_iterator, optimizer, loss_func)\n",
    "    valid_loss, valid_acc = eval_epoch(tagger, valid_iterator, loss_func)\n",
    "    epoch_secs = time.time() - t0\n",
    "\n",
    "    epoch_mins, epoch_secs = int(epoch_secs // 60), int(epoch_secs % 60)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(tagger.state_dict(), 'models/tut3-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Val. Loss: 0.237 | Val. Acc: 92.88%\nTest Loss: 0.254 | Test Acc: 91.49%\n"
    }
   ],
   "source": [
    "tagger.load_state_dict(torch.load('models/tut3-model.pt'))\n",
    "\n",
    "valid_loss, valid_acc = eval_epoch(tagger, valid_iterator, loss_func)\n",
    "test_loss, test_acc = eval_epoch(tagger, test_iterator, loss_func)\n",
    "\n",
    "print(f'Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}