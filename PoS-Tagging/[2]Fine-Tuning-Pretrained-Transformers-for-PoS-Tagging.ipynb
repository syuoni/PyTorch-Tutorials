{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Pretrained Transformers for PoS Tagging\n",
    "\n",
    "A BERT followed by a linear layer for Part-of-Speech (PoS) Tagging.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "SEED = 515\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "30522\n"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# tokenizer.save_pretrained('./transformers_cache/bert-base-uncased/')\n",
    "tokenizer = BertTokenizer.from_pretrained('./transformers_cache/bert-base-uncased/')\n",
    "print(len(tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['hello', 'world', 'how', 'are', 'you', '?']\n[7592, 2088, 2129, 2024, 2017, 1029]\n[101, 7592, 2088, 2129, 2024, 2017, 1029, 102]\n"
    }
   ],
   "source": [
    "# This will tokenize and lower case the data in a way that is consistent with the pre-trained transformer model.\n",
    "text = \"Hello WORLD how ARE yoU?\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)\n",
    "\n",
    "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(indexes)\n",
    "\n",
    "indexes = tokenizer.encode(text, add_special_tokens=True)\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[CLS] [SEP] [PAD] [UNK]\n"
    }
   ],
   "source": [
    "# `cls_token`: The classifier token which is used when doing sequence classification (classification of the whole\n",
    "# sequence instead of per-token classification). It is the first token of the sequence when built with special tokens.\n",
    "init_token = tokenizer.cls_token\n",
    "# `sep_token`: The separator token, which is used when building a sequence from multiple sequences, e.g. two sequences\n",
    "# for sequence classification or for a text and a question for question answering. It is also used as the last token of \n",
    "# a sequence built with special tokens.\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "101 102 0 100\n"
    }
   ],
   "source": [
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "512\n"
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "print(max_input_length)\n",
    "\n",
    "def cut_and_convert_to_ids(tokens, tokenizer, max_len):\n",
    "    # Add special `[CLS]` and `[SEP]` tokens to the start and end of the tokens\n",
    "    return tokenizer.convert_tokens_to_ids(tokens[:max_len-2])\n",
    "\n",
    "def cut_to_max_len(tags, max_len):\n",
    "    # Add special `[CLS]` and `[SEP]` tokens to the start and end of the tokens\n",
    "    return tags[:max_len-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "# Use `functools.partial` to pass functions with some of their arguments supplied\n",
    "text_preprocessor = functools.partial(cut_and_convert_to_ids, tokenizer=tokenizer, max_len=max_input_length)\n",
    "tag_preprocessor = functools.partial(cut_to_max_len, max_len=max_input_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "\n",
    "The dataset is Universal Dependencies English Web Treebank (UDPOS).  \n",
    "This dataset actually has two different sets of tags, [universal dependency (UD) tags](https://universaldependencies.org/u/pos/) and [Penn Treebank (PTB) tags](https://www.sketchengine.eu/penn-treebank-tagset/).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "# The data for PoS Tagging have already been tokenized, so NO need for a tokenizer\n",
    "# `use_vocab`: Whether to use a Vocab object. If False, the data in this field should already be numerical.\n",
    "TEXT = Field(batch_first=True, use_vocab=False, lower=True, preprocessing=text_preprocessor, \n",
    "             init_token=init_token_idx, eos_token=eos_token_idx, pad_token=pad_token_idx, unk_token=unk_token_idx,\n",
    "             include_lengths=True)\n",
    "\n",
    "# Because the set of possible tags is finite, do NOT use unknown token for it. \n",
    "# Add `<pad>` to both the start and end of tags, consistent to which has been done to the tokens. \n",
    "# Note the `<pad>` token will be ignored when calculating loss and accuracy. \n",
    "UD_TAGS = Field(batch_first=True, preprocessing=tag_preprocessor, \n",
    "                init_token='<pad>', eos_token='<pad>', unk_token=None, include_lengths=True)\n",
    "PTB_TAGS = Field(batch_first=True, preprocessing=tag_preprocessor, \n",
    "                 init_token='<pad>', eos_token='<pad>', unk_token=None, include_lengths=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import UDPOS\n",
    "\n",
    "fields = [('text', TEXT), ('udtags', UD_TAGS), ('ptbtags', PTB_TAGS)]\n",
    "train_data, valid_data, test_data = UDPOS.splits(fields=fields, root='data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[2632, 1011, 100, 1024, 2137, 2749, 2730, 100, 14093, 2632, 1011, 100, 1010, 1996, 14512, 2012, 1996, 8806, 1999, 1996, 2237, 1997, 100, 1010, 2379, 1996, 9042, 3675, 1012]\n['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']\n"
    }
   ],
   "source": [
    "print(train_data[0].text)\n",
    "print(train_data[0].udtags)\n",
    "print(train_data[0].ptbtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "18 51\n['<pad>', 'NOUN', 'PUNCT', 'VERB', 'PRON', 'ADP', 'DET', 'PROPN', 'ADJ', 'AUX', 'ADV', 'CCONJ', 'PART', 'NUM', 'SCONJ', 'X', 'INTJ', 'SYM']\n"
    }
   ],
   "source": [
    "UD_TAGS.build_vocab(train_data)\n",
    "PTB_TAGS.build_vocab(train_data)\n",
    "\n",
    "print(len(UD_TAGS.vocab), len(PTB_TAGS.vocab))\n",
    "print(UD_TAGS.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[  101,  2004,  2017,  ...,     0,     0,     0],\n        [  101,  2028,  2518,  ...,     0,     0,     0],\n        [  101,  2190,  1010,  ...,     0,     0,     0],\n        ...,\n        [  101, 11556,  2479,  ...,     0,     0,     0],\n        [  101,  1996, 18196,  ...,     0,     0,     0],\n        [  101, 12159,   102,  ...,     0,     0,     0]], device='cuda:3')\ntensor([21, 18,  4, 22, 46, 13, 31, 15, 12, 40, 24, 73, 19,  9, 17, 14,  9, 12,\n        14, 31, 22,  7, 44, 22, 27, 13, 13,  6, 24, 18, 33, 30,  4, 26, 62, 20,\n         6,  9,  6, 19, 28, 40, 36,  7,  4,  8,  3,  6, 25, 26, 35, 11, 18,  3,\n        22, 29, 28, 25, 22, 15, 16, 22, 31, 16,  9, 15,  8, 25, 17, 13, 16, 29,\n        33, 20,  4, 40, 54,  4,  4,  7,  9, 24,  9, 14, 18, 14,  7, 44, 20, 21,\n        17, 10, 13, 15,  5, 35,  9,  6,  9,  3], device='cuda:3')\ntensor([[ 0, 14,  4,  ...,  0,  0,  0],\n        [ 0, 13,  1,  ...,  0,  0,  0],\n        [ 0,  8,  2,  ...,  0,  0,  0],\n        ...,\n        [ 0,  7,  7,  ...,  0,  0,  0],\n        [ 0,  6,  1,  ...,  0,  0,  0],\n        [ 0,  7,  0,  ...,  0,  0,  0]], device='cuda:3')\ntensor([21, 18,  4, 22, 46, 13, 31, 15, 12, 40, 24, 73, 19,  9, 17, 14,  9, 12,\n        14, 31, 22,  7, 44, 22, 27, 13, 13,  6, 24, 18, 33, 30,  4, 26, 62, 20,\n         6,  9,  6, 19, 28, 40, 36,  7,  4,  8,  3,  6, 25, 26, 35, 11, 18,  3,\n        22, 29, 28, 25, 22, 15, 16, 22, 31, 16,  9, 15,  8, 25, 17, 13, 16, 29,\n        33, 20,  4, 40, 54,  4,  4,  7,  9, 24,  9, 14, 18, 14,  7, 44, 20, 21,\n        17, 10, 13, 15,  5, 35,  9,  6,  9,  3], device='cuda:3')\ntensor([True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True, True, True, True, True, True, True, True, True,\n        True, True, True, True], device='cuda:3')\n"
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    batch_text, batch_text_lens = batch.text\n",
    "    batch_tags, batch_tags_lens = batch.udtags\n",
    "    break\n",
    "\n",
    "print(batch_text)\n",
    "print(batch_text_lens)\n",
    "print(batch_tags)\n",
    "print(batch_tags_lens)\n",
    "\n",
    "print(batch_text_lens == batch_tags_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "`BertModel.forward`\n",
    "* Input\n",
    "    * `input_ids`: (batch, step)\n",
    "    * `attention_mask`: (batch, step)\n",
    "        * Mask to avoid performing attention on padding token indices  \n",
    "        * A `torch.FloatTensor` with values selected in `{0, 1}`; The value being `0` means `masked`, and the value being `1` means `not-masked` \n",
    "* Output\n",
    "    * `last_hidden_state`: (batch, step, hidden)\n",
    "        * Sequence of hidden-states at the output of the last layer of the model  \n",
    "    * `pooler_output`: (batch, hidden)\n",
    "        * Last layer hidden-state of the first token of the sequence (classification token)\n",
    "        * It will be further processed by a linear layer and a `tanh`, which was trained for next sentence prediction (classification) objective  \n",
    "    * `attentions`: tuple of (batch, head, step, step), returned when `config.output_attentions=True`  \n",
    "        * Attention weights after the `softmax`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "# bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "# bert.save_pretrained('./transformers_cache/bert-base-uncased/')\n",
    "\n",
    "# Set `output_attentions=True` to return attentions from `bert.forward`\n",
    "bert = BertModel.from_pretrained('./transformers_cache/bert-base-uncased/', output_attentions=True).to(device)\n",
    "bert.config.output_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([100, 73])\ntorch.Size([100, 73, 768])\ntorch.Size([100, 768])\n12 12\ntorch.Size([100, 12, 73, 73])\n"
    }
   ],
   "source": [
    "# mask: (batch, step)\n",
    "mask = (batch.text[0] != pad_token_idx).float()\n",
    "bert_outs, bert_pooled_outs, attens = bert(batch.text[0], attention_mask=mask)\n",
    "print(batch.text[0].size())\n",
    "print(bert_outs.size())\n",
    "print(bert_pooled_outs.size())\n",
    "\n",
    "print(len(attens), bert.config.num_hidden_layers)\n",
    "print(attens[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(2.9802e-07, device='cuda:3', grad_fn=<MaxBackward1>)\ntensor(True, device='cuda:3')\ntensor([[[0.0371, 0.0607, 0.0216,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0758, 0.0309, 0.0481,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0611, 0.0352, 0.0358,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0088, 0.0112, 0.0748,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0088, 0.0120, 0.0691,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0070, 0.0118, 0.0770,  ..., 0.0000, 0.0000, 0.0000]],\n\n        [[0.0360, 0.0951, 0.0281,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0832, 0.0308, 0.0522,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0587, 0.0141, 0.0430,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0107, 0.0171, 0.0850,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0104, 0.0145, 0.0789,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0085, 0.0161, 0.0877,  ..., 0.0000, 0.0000, 0.0000]],\n\n        [[0.1473, 0.0975, 0.1198,  ..., 0.0000, 0.0000, 0.0000],\n         [0.2599, 0.0979, 0.3725,  ..., 0.0000, 0.0000, 0.0000],\n         [0.2409, 0.2582, 0.2070,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.1258, 0.5453, 0.1646,  ..., 0.0000, 0.0000, 0.0000],\n         [0.1324, 0.5726, 0.1712,  ..., 0.0000, 0.0000, 0.0000],\n         [0.1012, 0.5972, 0.1579,  ..., 0.0000, 0.0000, 0.0000]],\n\n        ...,\n\n        [[0.1132, 0.0646, 0.0418,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0713, 0.2179, 0.1586,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0383, 0.2040, 0.1739,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0207, 0.2617, 0.1952,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0213, 0.2689, 0.1995,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0166, 0.2892, 0.1958,  ..., 0.0000, 0.0000, 0.0000]],\n\n        [[0.0734, 0.1666, 0.0730,  ..., 0.0000, 0.0000, 0.0000],\n         [0.1144, 0.1224, 0.0760,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0572, 0.0587, 0.0894,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0221, 0.0246, 0.2307,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0220, 0.0239, 0.2320,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0168, 0.0205, 0.2223,  ..., 0.0000, 0.0000, 0.0000]],\n\n        [[0.1786, 0.0881, 0.7334,  ..., 0.0000, 0.0000, 0.0000],\n         [0.1821, 0.3400, 0.4780,  ..., 0.0000, 0.0000, 0.0000],\n         [0.3403, 0.1772, 0.4825,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0734, 0.8321, 0.0945,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0753, 0.8554, 0.0693,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0589, 0.8589, 0.0822,  ..., 0.0000, 0.0000, 0.0000]]],\n       device='cuda:3', grad_fn=<SelectBackward>)\n"
    }
   ],
   "source": [
    "# Check whether the attention is 0 on padding positions \n",
    "print((attens[0].sum(dim=-1) - 1).abs().max())\n",
    "print(((attens[0] != 0) == mask.view(mask.size(0), 1, 1, -1)).all())\n",
    "\n",
    "# Show the first head attention\n",
    "print(attens[0][:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[  101,  2004,  2017,  ...,     0,     0,     0],\n        [  101,  2028,  2518,  ...,     0,     0,     0],\n        [  101,  2190,  1010,  ...,     0,     0,     0],\n        ...,\n        [  101, 11556,  2479,  ...,     0,     0,     0],\n        [  101,  1996, 18196,  ...,     0,     0,     0],\n        [  101, 12159,   102,  ...,     0,     0,     0]], device='cuda:3')\ntensor([[[ 0.0769, -0.0570,  0.2451,  ..., -0.2046,  0.6273,  0.4673],\n         [ 0.4734,  0.3849,  0.9369,  ..., -0.3964,  0.8343, -0.1047],\n         [-0.2909, -0.4783,  0.4526,  ...,  0.0791,  1.0221, -0.1757],\n         ...,\n         [ 0.9056, -0.0645,  0.1375,  ..., -0.0397,  0.9553, -0.7583],\n         [ 0.9373, -0.0585,  0.2285,  ..., -0.0013,  0.7479, -0.7201],\n         [ 0.4119, -0.0657,  0.3063,  ...,  0.2168,  0.4914, -0.3562]],\n\n        [[-0.1209,  0.1067, -0.0999,  ..., -0.1584,  0.2379,  0.7386],\n         [-0.0933, -0.6518, -0.5936,  ...,  0.4867,  0.4932,  0.4381],\n         [-0.2321,  0.2492, -0.4463,  ...,  0.5528,  0.3573,  0.1935],\n         ...,\n         [ 0.1667,  0.2268,  0.3511,  ...,  0.4824, -0.2362,  0.1935],\n         [-0.3695, -0.6788, -0.2723,  ...,  0.7578,  0.2679,  0.0277],\n         [ 0.2825, -0.1927,  0.3387,  ...,  0.3327,  0.0315,  0.1416]],\n\n        [[-0.3413, -0.1676,  0.0666,  ..., -0.0840,  0.6023,  0.2980],\n         [-0.9700, -0.0442,  0.3747,  ..., -0.0295,  0.4770, -0.7113],\n         [-0.4982, -0.4454, -0.0086,  ...,  0.2332,  0.3803, -0.0201],\n         ...,\n         [-0.7333, -0.6423,  0.2596,  ...,  0.2143,  0.1481, -0.3002],\n         [-0.5251, -0.3064,  0.3781,  ...,  0.0905,  0.0211, -0.3148],\n         [-0.6678, -0.4805,  0.2595,  ...,  0.1571,  0.0355, -0.3236]],\n\n        ...,\n\n        [[-0.4934, -0.2669, -0.1856,  ..., -0.6876,  0.3055,  0.2346],\n         [ 1.0988, -0.1882, -0.0568,  ...,  0.2086, -0.0550, -0.1160],\n         [-0.4190, -0.3110, -0.2545,  ..., -0.6209, -0.4518, -0.3380],\n         ...,\n         [-0.3562, -0.3118, -0.2545,  ..., -0.1383,  0.1892,  0.0470],\n         [-0.2080, -0.2313, -0.1832,  ...,  0.0305,  0.1275,  0.0552],\n         [-0.3757, -0.3061, -0.2184,  ..., -0.0678,  0.0883, -0.0517]],\n\n        [[ 0.0364,  0.2880,  0.0624,  ..., -0.1706,  0.2449,  0.3727],\n         [-0.5426, -0.1838, -0.3002,  ..., -0.3976,  0.5378, -0.2557],\n         [-0.1732,  0.1727,  0.4175,  ..., -0.0925,  0.1351,  0.2220],\n         ...,\n         [ 0.3643,  0.2907,  0.5759,  ...,  0.2581,  0.2047,  0.0332],\n         [ 0.3193,  0.3410,  0.5936,  ...,  0.2091,  0.1633,  0.0302],\n         [ 0.1661,  0.2301,  0.6187,  ...,  0.2906,  0.3946, -0.0956]],\n\n        [[-0.1593,  0.1934,  0.0695,  ..., -0.2178,  0.2308, -0.0763],\n         [-0.0890,  0.1785, -0.0031,  ...,  0.2243,  0.2553,  0.3935],\n         [ 0.7546,  0.2114, -0.3046,  ...,  0.0095, -0.7387, -0.3083],\n         ...,\n         [-0.2013,  0.4360,  0.3684,  ..., -0.0458,  0.0411,  0.3264],\n         [-0.2290,  0.3644,  0.3933,  ..., -0.0058,  0.0408,  0.3767],\n         [-0.3110,  0.2126,  0.3182,  ...,  0.0964,  0.0960,  0.2653]]],\n       device='cuda:3', grad_fn=<NativeLayerNormBackward>)\n"
    }
   ],
   "source": [
    "# The values at padding positions are NOT zeros? \n",
    "# Yes, but they will never pollute the non-padding positions, since the attentions are applied with masking. \n",
    "print(batch.text[0])\n",
    "print(bert_outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using an embedding layer to get embeddings for our text, we'll be using the pre-trained transformer model. These embeddings will then be fed into a linear layer to predict the tag for each token.  \n",
    "\n",
    "We get the embedding dimension size (called the `hidden_size`) from the transformer via its config attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoSTagger(nn.Module):\n",
    "    def __init__(self, bert, tag_dim, dropout):\n",
    "        super().__init__()\n",
    "        # Use `bert` to provide word embeddings. \n",
    "        self.bert = bert\n",
    "        emb_dim = bert.config.hidden_size\n",
    "        \n",
    "        self.fc = nn.Linear(emb_dim, tag_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text/mask: (batch, step)\n",
    "        mask = (text != self.bert.config.pad_token_id).float()\n",
    "        embedded, *_ = self.bert(text, attention_mask=mask)\n",
    "\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # preds: (batch, step, tag_dim)\n",
    "        preds = self.fc(embedded)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([100, 73])\ntorch.Size([100, 73, 18])\n"
    }
   ],
   "source": [
    "TAG_DIM = len(UD_TAGS.vocab)\n",
    "# TAG_DIM = len(PTB_TAGS.vocab)\n",
    "\n",
    "DROPOUT = 0.25\n",
    "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
    "# TAG_PAD_IDX = PTB_TAGS.vocab.stoi[PTB_TAGS.pad_token]\n",
    "\n",
    "\n",
    "tagger = PoSTagger(bert, TAG_DIM, DROPOUT).to(device)\n",
    "preds = tagger(batch_text)\n",
    "\n",
    "print(batch_text.size())\n",
    "print(preds.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(0., device='cuda:3', grad_fn=<MaxBackward1>)"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Check if data are mixed across different samples in a batch.\n",
    "tagger.eval()\n",
    "preds_012 = tagger(batch_text[0:3, :])\n",
    "preds_123 = tagger(batch_text[1:4, :])\n",
    "\n",
    "(preds_012[1:] - preds_123[:2]).abs().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The model has 109,496,082 trainable parameters\n"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Count trainable parameters. \n",
    "    \"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(tagger):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "optimizer = optim.AdamW(tagger.parameters(), lr=LEARNING_RATE)\n",
    "loss_func = nn.CrossEntropyLoss(ignore_index=TAG_PAD_IDX, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(tagger, iterator, optimizer, loss_func):\n",
    "    tagger.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for batch in iterator:\n",
    "        # Forward pass\n",
    "        text, text_lens = batch.text\n",
    "        tags, tags_lens = batch.udtags\n",
    "        preds = tagger(text)\n",
    "\n",
    "        # Calculate loss\n",
    "        preds_flattened = preds.view(-1, preds.size(-1))\n",
    "        tags_flattened = tags.flatten()\n",
    "        loss = loss_func(preds_flattened, tags_flattened)\n",
    "\n",
    "        # Backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Accumulate loss and acc\n",
    "        epoch_loss += loss.item()\n",
    "        non_padding = (tags_flattened != loss_func.ignore_index)\n",
    "        epoch_acc += (preds_flattened.argmax(dim=-1) == tags_flattened)[non_padding].sum().item() / non_padding.sum().item()\n",
    "    return epoch_loss/len(iterator), epoch_acc/len(iterator)\n",
    "\n",
    "def eval_epoch(tagger, iterator, loss_func):\n",
    "    tagger.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            # Forward pass\n",
    "            text, text_lens = batch.text\n",
    "            tags, tags_lens = batch.udtags\n",
    "            preds = tagger(text)\n",
    "\n",
    "            # Calculate loss\n",
    "            preds_flattened = preds.view(-1, preds.size(-1))\n",
    "            tags_flattened = tags.flatten()\n",
    "            loss = loss_func(preds_flattened, tags_flattened)\n",
    "            \n",
    "            # Accumulate loss and acc\n",
    "            epoch_loss += loss.item()\n",
    "            non_padding = (tags_flattened != loss_func.ignore_index)\n",
    "            epoch_acc += (preds_flattened.argmax(dim=-1) == tags_flattened)[non_padding].sum().item() / non_padding.sum().item()\n",
    "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch: 01 | Epoch Time: 0m 50s\n\tTrain Loss: 0.522 | Train Acc: 85.65%\n\t Val. Loss: 0.276 |  Val. Acc: 91.74%\nEpoch: 02 | Epoch Time: 0m 49s\n\tTrain Loss: 0.137 | Train Acc: 96.05%\n\t Val. Loss: 0.242 |  Val. Acc: 92.54%\nEpoch: 03 | Epoch Time: 0m 50s\n\tTrain Loss: 0.095 | Train Acc: 97.24%\n\t Val. Loss: 0.250 |  Val. Acc: 92.53%\nEpoch: 04 | Epoch Time: 0m 50s\n\tTrain Loss: 0.069 | Train Acc: 98.05%\n\t Val. Loss: 0.243 |  Val. Acc: 92.59%\nEpoch: 05 | Epoch Time: 0m 51s\n\tTrain Loss: 0.050 | Train Acc: 98.53%\n\t Val. Loss: 0.246 |  Val. Acc: 93.00%\nEpoch: 06 | Epoch Time: 0m 51s\n\tTrain Loss: 0.039 | Train Acc: 98.86%\n\t Val. Loss: 0.244 |  Val. Acc: 93.25%\nEpoch: 07 | Epoch Time: 0m 50s\n\tTrain Loss: 0.030 | Train Acc: 99.16%\n\t Val. Loss: 0.262 |  Val. Acc: 93.62%\nEpoch: 08 | Epoch Time: 0m 50s\n\tTrain Loss: 0.024 | Train Acc: 99.32%\n\t Val. Loss: 0.274 |  Val. Acc: 93.43%\nEpoch: 09 | Epoch Time: 0m 50s\n\tTrain Loss: 0.019 | Train Acc: 99.45%\n\t Val. Loss: 0.286 |  Val. Acc: 93.24%\nEpoch: 10 | Epoch Time: 0m 50s\n\tTrain Loss: 0.015 | Train Acc: 99.55%\n\t Val. Loss: 0.289 |  Val. Acc: 93.51%\n"
    }
   ],
   "source": [
    "import time\n",
    "N_EPOCHS = 10\n",
    "best_valid_loss = np.inf\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    t0 = time.time()\n",
    "    train_loss, train_acc = train_epoch(tagger, train_iterator, optimizer, loss_func)\n",
    "    valid_loss, valid_acc = eval_epoch(tagger, valid_iterator, loss_func)\n",
    "    epoch_secs = time.time() - t0\n",
    "\n",
    "    epoch_mins, epoch_secs = int(epoch_secs // 60), int(epoch_secs % 60)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(tagger.state_dict(), 'models/tut2-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Val. Loss: 0.242 | Val. Acc: 92.54%\nTest Loss: 0.260 | Test Acc: 91.54%\n"
    }
   ],
   "source": [
    "tagger.load_state_dict(torch.load('models/tut2-model.pt'))\n",
    "\n",
    "valid_loss, valid_acc = eval_epoch(tagger, valid_iterator, loss_func)\n",
    "test_loss, test_acc = eval_epoch(tagger, test_iterator, loss_func)\n",
    "\n",
    "print(f'Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}