{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "%matplotlib inline\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135842,\n",
       " [['go .', 'va ! '],\n",
       "  ['run !', 'cours ! '],\n",
       "  ['run !', 'courez ! '],\n",
       "  ['wow !', 'ca alors ! '],\n",
       "  ['fire !', 'au feu ! ']])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2idx = {}\n",
    "        self.word2count = {}\n",
    "        self.idx2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def add_sent(self, sent):\n",
    "        for word in sent.split():\n",
    "            self.add_word(word)\n",
    "            \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.idx2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "def unicode2ascii(s):\n",
    "    return ''.join([c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn'])\n",
    "\n",
    "def norm_string(s):\n",
    "    s = unicode2ascii(s.lower().strip(' '))\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "with open('data/eng-fra.txt', encoding='utf-8') as f:\n",
    "    pairs = [[norm_string(s) for s in line.split('\\t')] for line in f]\n",
    "\n",
    "len(pairs), pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11111 [['i m .', 'j ai ans . '], ['i m ok .', 'je vais bien . '], ['i m ok .', 'ca va . '], ['i m fat .', 'je suis gras . '], ['i m fat .', 'je suis gros . ']]\n",
      "eng 2998\n",
      "fra 4582\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "pairs = [pair for pair in pairs if len(pair[0].split(' ')) <= MAX_LEN and \\\n",
    "                                   len(pair[1].split(' ')) <= MAX_LEN and \\\n",
    "                                   pair[0].startswith(eng_prefixes)]\n",
    "print(len(pairs), pairs[:5])\n",
    "\n",
    "in_lang = Lang('eng')\n",
    "out_lang = Lang('fra')\n",
    "for pair in pairs:\n",
    "    in_lang.add_sent(pair[0])\n",
    "    out_lang.add_sent(pair[1])\n",
    "print(in_lang.name, in_lang.n_words)\n",
    "print(out_lang.name, out_lang.n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU: gated recurrent unit\n",
    "\n",
    "Math formulas: \n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "r_t = \\mathrm{sigmoid}(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n",
    "z_t = \\mathrm{sigmoid}(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n",
    "n_t = \\tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n",
    "h_t = (1 - z_t) * n_t + z_t * h_{(t-1)} \\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.emb = nn.Embedding(in_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, ins, hidden):\n",
    "        emb_ins = self.emb(ins)\n",
    "        outs = emb_ins.view(1, 1, -1)\n",
    "        for i in range(self.n_layers):\n",
    "            outs, hidden = self.gru(outs, hidden)\n",
    "        return outs, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return hidden.cuda()\n",
    "        else:\n",
    "            return hidden\n",
    "        \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, out_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.emb = nn.Embedding(out_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.outs = nn.Linear(hidden_size, out_size)\n",
    "        \n",
    "    def forward(self, ins, hidden):\n",
    "        emb_outs = self.emb(ins)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn.GRU?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
