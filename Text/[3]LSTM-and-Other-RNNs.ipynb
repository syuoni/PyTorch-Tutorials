{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n",
    "![LSTM](fig/LSTM.jpg)\n",
    "\n",
    "Math formulas:  \n",
    "$$\n",
    "\\begin{aligned}\n",
    "i_t &= \\mathrm{sigmoid}(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\\\\n",
    "f_t &= \\mathrm{sigmoid}(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\\\\n",
    "g_t &= \\tanh(W_{ig} x_t + b_{ig} + W_{hc} h_{(t-1)} + b_{hg}) \\\\\n",
    "o_t &= \\mathrm{sigmoid}(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\\\\n",
    "c_t &= f_t * c_{(t-1)} + i_t * g_t \\\\\n",
    "h_t &= o_t * \\tanh(c_t)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "LSTM expects all of its inputs to be 3D tensors:  \n",
    "* 1st dimension: sequence (along words in a sentence)  \n",
    "* 2nd dimension: mini-batch  \n",
    "* 3rd dimension: elements (embedding vector)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Parameter containing:\ntensor([[-0.0053,  0.3793, -0.5820],\n        [-0.5204, -0.2723,  0.1896],\n        [-0.0140,  0.5607, -0.0628],\n        [ 0.1871, -0.2137, -0.1390],\n        [-0.6755, -0.4683, -0.2915],\n        [ 0.0262,  0.2795,  0.4243],\n        [-0.4794, -0.3079,  0.2568],\n        [ 0.5872, -0.1455,  0.5291]], requires_grad=True)\nParameter containing:\ntensor([[-0.1140,  0.0748],\n        [ 0.6403, -0.6560],\n        [-0.4452, -0.1790],\n        [-0.2756,  0.6109],\n        [-0.4583, -0.3255],\n        [-0.4940, -0.6622],\n        [-0.4128,  0.6078],\n        [ 0.3155,  0.3427]], requires_grad=True)\nParameter containing:\ntensor([ 0.0372, -0.3625,  0.1196, -0.6602, -0.5109, -0.3645,  0.4461,  0.4146],\n       requires_grad=True)\nParameter containing:\ntensor([-0.3136, -0.0255,  0.4522,  0.7030,  0.2806,  0.0955,  0.4741, -0.4163],\n       requires_grad=True)\n"
    }
   ],
   "source": [
    "# Specify the random seed. \n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 3 input dimensions, 2 hidden dimensions, 1 layer. \n",
    "lstm = nn.LSTM(3, 2)\n",
    "\n",
    "# (W_ii|W_if|W_ig|W_io)\n",
    "print(lstm.weight_ih_l0)\n",
    "# (W_hi|W_hf|W_hg|W_ho)\n",
    "print(lstm.weight_hh_l0)\n",
    "# (b_ii|b_if|b_ig|b_io)\n",
    "print(lstm.bias_ih_l0)\n",
    "# (b_ii|b_if|b_ig|b_io)\n",
    "print(lstm.bias_hh_l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[-0.0209, -0.7185,  0.5186]]])\ntensor([[[ 0.4164, -0.4423]]], grad_fn=<StackBackward>)\ntensor([[[ 0.4164, -0.4423]]], grad_fn=<StackBackward>)\ntensor([[[ 0.5179, -1.3637]]], grad_fn=<StackBackward>)\n"
    }
   ],
   "source": [
    "# 1 seq length, 1 batch size, 3 embedding dimensions. \n",
    "in1 = torch.randn(1, 1, 3)\n",
    "print(in1)\n",
    "\n",
    "# Initialize the hidden state, which is (h_0, c_0) in LSTM structure picture. \n",
    "hidden0 = (torch.randn(1, 1, 2),\n",
    "           torch.randn(1, 1, 2))\n",
    "\n",
    "# Pass throught the LSTM cell. \n",
    "out1, hidden1 = lstm(in1, hidden0)\n",
    "print(out1)\n",
    "print(hidden1[0])\n",
    "print(hidden1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 0.4164, -0.4423]], grad_fn=<MulBackward0>)\ntensor([[ 0.5179, -1.3637]], grad_fn=<AddBackward0>)\n"
    }
   ],
   "source": [
    "# Manually calculate the LSTM\n",
    "# Shape of (1, 2*4)\n",
    "W_ih_xb = in1[0].mm(lstm.weight_ih_l0.T) + lstm.bias_ih_l0\n",
    "W_hh_xb = hidden0[0][0].mm(lstm.weight_hh_l0.T) + lstm.bias_hh_l0\n",
    "\n",
    "# Shape of (1, 2)\n",
    "i1 = F.sigmoid((W_ih_xb + W_hh_xb)[:, 0:2])\n",
    "f1 = F.sigmoid((W_ih_xb + W_hh_xb)[:, 2:4])\n",
    "g1 = F.tanh((W_ih_xb + W_hh_xb)[:, 4:6])\n",
    "o1 = F.sigmoid((W_ih_xb + W_hh_xb)[:, 6:8])\n",
    "c1 = f1 * hidden0[1][0] + i1 * g1\n",
    "h1 = o1 * F.tanh(c1)\n",
    "\n",
    "print(h1)\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM: Step the Sequence One Element at a Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[0.0083, 0.1808]]], grad_fn=<StackBackward>)\n(tensor([[[0.0083, 0.1808]]], grad_fn=<StackBackward>), tensor([[[0.0114, 0.4527]]], grad_fn=<StackBackward>))\ntensor([[[0.1124, 0.0478]]], grad_fn=<StackBackward>)\n(tensor([[[0.1124, 0.0478]]], grad_fn=<StackBackward>), tensor([[[0.1329, 0.1232]]], grad_fn=<StackBackward>))\ntensor([[[ 0.4619, -0.0474]]], grad_fn=<StackBackward>)\n(tensor([[[ 0.4619, -0.0474]]], grad_fn=<StackBackward>), tensor([[[ 0.6229, -0.3593]]], grad_fn=<StackBackward>))\ntensor([[[ 0.2640, -0.1513]]], grad_fn=<StackBackward>)\n(tensor([[[ 0.2640, -0.1513]]], grad_fn=<StackBackward>), tensor([[[ 0.4306, -0.4890]]], grad_fn=<StackBackward>))\ntensor([[[ 0.0712, -0.1522]]], grad_fn=<StackBackward>)\n(tensor([[[ 0.0712, -0.1522]]], grad_fn=<StackBackward>), tensor([[[ 0.1088, -0.3212]]], grad_fn=<StackBackward>))\n"
    }
   ],
   "source": [
    "# Specify the random seed. \n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 3 input dimensions, 2 hidden dimensions, 1 layer. \n",
    "lstm = nn.LSTM(3, 2)\n",
    "\n",
    "# 5 seq length, 1 batch size, 3 embedding dimensions. \n",
    "ins = torch.randn(5, 1, 3)\n",
    "\n",
    "# Initialize the hidden state, which is (h_0, c_0) in LSTM structure picture. \n",
    "hidden = (torch.randn(1, 1, 2),\n",
    "          torch.randn(1, 1, 2))\n",
    "\n",
    "# Step through the sequence one element at a time.\n",
    "for ins_i in ins:\n",
    "    out, hidden = lstm(ins_i.view(1, 1, -1), hidden)\n",
    "    # out is always the first of two elements of hidden\n",
    "    # hidden is (h_t, c_t) in LSTM structure picture. \n",
    "    print(out)\n",
    "    print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM: Step the Sequence All at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[ 0.0083,  0.1808]],\n\n        [[ 0.1124,  0.0478]],\n\n        [[ 0.4619, -0.0474]],\n\n        [[ 0.2640, -0.1513]],\n\n        [[ 0.0712, -0.1522]]], grad_fn=<StackBackward>)\n(tensor([[[ 0.0712, -0.1522]]], grad_fn=<StackBackward>), tensor([[[ 0.1088, -0.3212]]], grad_fn=<StackBackward>))\n"
    }
   ],
   "source": [
    "# Specify the random seed. \n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 3 input dimensions, 2 hidden dimensions, 1 layer. \n",
    "lstm = nn.LSTM(3, 2)\n",
    "\n",
    "# 5 seq length, 1 batch size, 3 embedding dimensions. \n",
    "ins = torch.randn(5, 1, 3)\n",
    "\n",
    "# Initialize the hidden state, which is (h_0, c_0) in LSTM structure picture. \n",
    "hidden = (torch.randn(1, 1, 2),\n",
    "          torch.randn(1, 1, 2))\n",
    "\n",
    "# do the entire sequence all at once.\n",
    "outs, hidden = lstm(ins, hidden)\n",
    "print(outs)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[ 0.1108, -0.0602]],\n\n        [[ 0.1081,  0.0063]],\n\n        [[ 0.0357,  0.0238]],\n\n        [[ 0.0341,  0.0623]],\n\n        [[ 0.0752,  0.1061]]], grad_fn=<StackBackward>)\n(tensor([[[0.0752, 0.1061]]], grad_fn=<StackBackward>), tensor([[[0.1004, 0.2453]]], grad_fn=<StackBackward>))\n"
    }
   ],
   "source": [
    "# Use the output-sequence as the input-sequence of the next LSTM-layer\n",
    "# Use the last hidden state as the initial hidden state of the next LSTM-layer\n",
    "\n",
    "lstm_next = nn.LSTM(2, 2)\n",
    "\n",
    "outs, hidden = lstm_next(outs, hidden)\n",
    "print(outs)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM: Batched Input and Output of LSTM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([5, 16, 2])\ntorch.Size([1, 16, 2]) torch.Size([1, 16, 2])\n"
    }
   ],
   "source": [
    "# Specify the random seed. \n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 3 input dimensions, 2 hidden dimensions, 1 layer. \n",
    "lstm = nn.LSTM(3, 2)\n",
    "\n",
    "# Batch input & output\n",
    "# 5 seq length, 16 batch size, 3 embedding dimensions. \n",
    "ins = torch.randn(5, 16, 3)\n",
    "\n",
    "# The initial hidden state should be the same across mini-batches\n",
    "hidden = (torch.zeros(1, 16, 2),\n",
    "          torch.zeros(1, 16, 2))\n",
    "\n",
    "outs, hidden = lstm(ins, hidden)\n",
    "print(outs.size())\n",
    "print(hidden[0].size(), hidden[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM: Batch-First Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([16, 5, 2])\ntorch.Size([1, 16, 2]) torch.Size([1, 16, 2])\n"
    }
   ],
   "source": [
    "# Specify the random seed. \n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 3 input dimensions, 2 hidden dimensions, 1 layer. \n",
    "lstm = nn.LSTM(3, 2, batch_first=True)\n",
    "\n",
    "# Batch input & output\n",
    "# 5 seq length, 16 batch size, 3 embedding dimensions. \n",
    "ins = torch.randn(16, 5, 3)\n",
    "\n",
    "# The initial hidden state should be the same across mini-batches\n",
    "# NOTE: the batch size is still in the second place.\n",
    "hidden = (torch.zeros(1, 16, 2),\n",
    "          torch.zeros(1, 16, 2))\n",
    "\n",
    "outs, hidden = lstm(ins, hidden)\n",
    "print(outs.size())\n",
    "print(hidden[0].size(), hidden[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM: Packed (Masked) Input and Output of LSTM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[ 0.2055, -0.4503, -0.5731],\n         [-0.5554,  0.5943,  1.5419],\n         [ 0.5073, -0.5910, -1.3253],\n         [ 0.1886, -0.0691, -0.4949],\n         [-1.4959, -0.1938,  0.4455]],\n\n        [[ 1.3253,  1.5091,  2.0820],\n         [ 1.7067,  2.3804, -1.1256],\n         [-0.3170, -1.0925, -0.0852],\n         [ 0.3276, -0.7607, -1.5991],\n         [ 0.0185, -0.7504,  0.1854]],\n\n        [[ 0.6211,  0.6382, -0.0033],\n         [-0.5344,  1.1687,  0.3945],\n         [ 1.9415,  0.7915, -0.0203],\n         [-0.4372, -1.5353, -0.4127],\n         [ 0.9663,  1.6248,  0.9625]],\n\n        [[ 0.3492, -0.9215, -0.0562],\n         [-0.7015,  1.0367, -0.6037],\n         [-1.2788,  0.1239,  1.1648],\n         [ 0.9234,  1.3873,  1.3750],\n         [ 0.6596,  0.4766, -1.0163]]])"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Specify the random seed. \n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 3 input dimensions, 2 hidden dimensions, 1 layer. \n",
    "# Use batch-first to show the input and output more clearly. \n",
    "lstm = nn.LSTM(3, 2, batch_first=True)\n",
    "\n",
    "# Masked input & output\n",
    "# 5 seq length, 4 batch size, 3 embedding dimensions. \n",
    "ins = torch.randn(4, 5, 3)\n",
    "ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PackedSequence(data=tensor([[ 0.2055, -0.4503, -0.5731],\n        [ 1.3253,  1.5091,  2.0820],\n        [ 0.6211,  0.6382, -0.0033],\n        [ 0.3492, -0.9215, -0.0562],\n        [-0.5554,  0.5943,  1.5419],\n        [ 1.7067,  2.3804, -1.1256],\n        [-0.5344,  1.1687,  0.3945],\n        [-0.7015,  1.0367, -0.6037],\n        [ 0.5073, -0.5910, -1.3253],\n        [-0.3170, -1.0925, -0.0852],\n        [ 1.9415,  0.7915, -0.0203],\n        [ 0.1886, -0.0691, -0.4949],\n        [ 0.3276, -0.7607, -1.5991],\n        [-0.4372, -1.5353, -0.4127],\n        [-1.4959, -0.1938,  0.4455],\n        [ 0.0185, -0.7504,  0.1854]]), batch_sizes=tensor([4, 4, 3, 3, 2]), sorted_indices=None, unsorted_indices=None)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# The sequences have to be sorted in a decreasing order according to their lengths. \n",
    "# The four sentences have 5, 5, 4, 2 valid words, respectively. \n",
    "packed_ins = pack_padded_sequence(ins, lengths=[5, 5, 4, 2], batch_first=True)\n",
    "packed_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([[[ 0.2055, -0.4503, -0.5731],\n          [-0.5554,  0.5943,  1.5419],\n          [ 0.5073, -0.5910, -1.3253],\n          [ 0.1886, -0.0691, -0.4949],\n          [-1.4959, -0.1938,  0.4455]],\n \n         [[ 1.3253,  1.5091,  2.0820],\n          [ 1.7067,  2.3804, -1.1256],\n          [-0.3170, -1.0925, -0.0852],\n          [ 0.3276, -0.7607, -1.5991],\n          [ 0.0185, -0.7504,  0.1854]],\n \n         [[ 0.6211,  0.6382, -0.0033],\n          [-0.5344,  1.1687,  0.3945],\n          [ 1.9415,  0.7915, -0.0203],\n          [-0.4372, -1.5353, -0.4127],\n          [ 0.0000,  0.0000,  0.0000]],\n \n         [[ 0.3492, -0.9215, -0.0562],\n          [-0.7015,  1.0367, -0.6037],\n          [ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000]]]),\n tensor([5, 5, 4, 2]))"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# The values outside the specified valid lengths in original input are lost. \n",
    "pad_packed_sequence(packed_ins, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PackedSequence(data=tensor([[ 0.0029, -0.0991],\n        [-0.1605,  0.1643],\n        [-0.2102, -0.0125],\n        [-0.0048, -0.1174],\n        [-0.1077,  0.1164],\n        [-0.2453,  0.0519],\n        [-0.3288,  0.0454],\n        [-0.0139, -0.0448],\n        [-0.0145, -0.0406],\n        [-0.2614, -0.0780],\n        [-0.3299,  0.0585],\n        [-0.0623, -0.0949],\n        [ 0.0572, -0.1128],\n        [-0.1017, -0.1055],\n        [ 0.1499, -0.0470],\n        [ 0.0512, -0.1822]], grad_fn=<CatBackward>), batch_sizes=tensor([4, 4, 3, 3, 2]), sorted_indices=None, unsorted_indices=None)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Pass through the LSTM\n",
    "# NOTE: the batch size is still in the second place.\n",
    "hidden = (torch.zeros(1, 4, 2),\n",
    "          torch.zeros(1, 4, 2))\n",
    "\n",
    "packed_outs, hidden = lstm(packed_ins, hidden)\n",
    "packed_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[ 0.0029, -0.0991],\n         [-0.1077,  0.1164],\n         [-0.0145, -0.0406],\n         [-0.0623, -0.0949],\n         [ 0.1499, -0.0470]],\n\n        [[-0.1605,  0.1643],\n         [-0.2453,  0.0519],\n         [-0.2614, -0.0780],\n         [ 0.0572, -0.1128],\n         [ 0.0512, -0.1822]],\n\n        [[-0.2102, -0.0125],\n         [-0.3288,  0.0454],\n         [-0.3299,  0.0585],\n         [-0.1017, -0.1055],\n         [ 0.0000,  0.0000]],\n\n        [[-0.0048, -0.1174],\n         [-0.0139, -0.0448],\n         [ 0.0000,  0.0000],\n         [ 0.0000,  0.0000],\n         [ 0.0000,  0.0000]]], grad_fn=<TransposeBackward0>)\ntensor([5, 5, 4, 2])\n"
    }
   ],
   "source": [
    "outs, lengths = pad_packed_sequence(packed_outs, batch_first=True)\n",
    "print(outs)\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([[[ 0.1499, -0.0470],\n          [ 0.0512, -0.1822],\n          [-0.1017, -0.1055],\n          [-0.0139, -0.0448]]], grad_fn=<StackBackward>),\n tensor([[[ 0.1771, -0.1396],\n          [ 0.0684, -0.3450],\n          [-0.1215, -0.2590],\n          [-0.0207, -0.1593]]], grad_fn=<StackBackward>))"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM: Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PackedSequence(data=tensor([[-0.2188, -2.4351, -0.0729],\n        [ 1.3873, -0.8834, -0.4189],\n        [-0.3126,  0.2458, -0.2596],\n        [-1.1964,  0.1970, -1.1773],\n        [-0.0340,  0.9625,  0.3492],\n        [-0.8048,  0.5656,  0.6104],\n        [ 0.1183,  0.2440,  1.1646],\n        [-0.0661, -0.3584, -1.5616],\n        [-0.9215, -0.0562, -0.6227],\n        [ 0.4669,  1.9507, -1.0631],\n        [ 0.2886,  0.3866, -0.2011],\n        [-0.4637,  1.9218, -0.4025],\n        [-0.0773,  0.1164, -0.5940],\n        [-0.1179,  0.1922, -0.7722],\n        [ 0.1239,  1.1648,  0.9234],\n        [-1.2439, -0.1021, -1.0335]]), batch_sizes=tensor([4, 4, 3, 3, 2]), sorted_indices=None, unsorted_indices=None)"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Specify the random seed. \n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 3 input dimensions, 2 hidden dimensions, 1 layer. \n",
    "bi_lstm = nn.LSTM(3, 2, batch_first=True, bidirectional=True)\n",
    "\n",
    "# Masked input & output\n",
    "# 5 seq length, 4 batch size, 3 embedding dimensions. \n",
    "ins = torch.randn(4, 5, 3)\n",
    "\n",
    "# The sequences have to be sorted in a decreasing order according to their lengths. \n",
    "# The four sentences have 5, 5, 4, 2 valid words, respectively. \n",
    "packed_ins = pack_padded_sequence(ins, lengths=[5, 5, 4, 2], batch_first=True)\n",
    "packed_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PackedSequence(data=tensor([[ 0.1599, -0.2296, -0.0549,  0.0859],\n        [-0.1351, -0.1073,  0.1882,  0.0390],\n        [-0.0206, -0.0524,  0.1111,  0.2702],\n        [ 0.3011, -0.0614,  0.0943,  0.0871],\n        [-0.0967, -0.0438,  0.1588,  0.2738],\n        [-0.1369,  0.0257,  0.0899,  0.3400],\n        [-0.1503,  0.0542,  0.0921,  0.2098],\n        [ 0.2555, -0.1526,  0.1258, -0.1127],\n        [ 0.1514, -0.0751,  0.0661,  0.2950],\n        [-0.3010,  0.0029,  0.2636,  0.1700],\n        [-0.2395, -0.0082,  0.1821,  0.1473],\n        [-0.1441, -0.0259,  0.1622,  0.3950],\n        [-0.3154, -0.0406,  0.1405,  0.1216],\n        [-0.1410, -0.0510,  0.1272,  0.0702],\n        [-0.3265,  0.0767,  0.0860,  0.2457],\n        [ 0.1149, -0.0599,  0.0452,  0.1205]], grad_fn=<CatBackward>), batch_sizes=tensor([4, 4, 3, 3, 2]), sorted_indices=None, unsorted_indices=None)"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Pass through the LSTM\n",
    "# NOTE: the batch size is still in the second place.\n",
    "hidden = (torch.zeros(2, 4, 2),\n",
    "          torch.zeros(2, 4, 2))\n",
    "\n",
    "packed_outs, hidden = bi_lstm(packed_ins, hidden)\n",
    "packed_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[ 0.1599, -0.2296, -0.0549,  0.0859],\n         [-0.0967, -0.0438,  0.1588,  0.2738],\n         [ 0.1514, -0.0751,  0.0661,  0.2950],\n         [-0.1441, -0.0259,  0.1622,  0.3950],\n         [-0.3265,  0.0767,  0.0860,  0.2457]],\n\n        [[-0.1351, -0.1073,  0.1882,  0.0390],\n         [-0.1369,  0.0257,  0.0899,  0.3400],\n         [-0.3010,  0.0029,  0.2636,  0.1700],\n         [-0.3154, -0.0406,  0.1405,  0.1216],\n         [ 0.1149, -0.0599,  0.0452,  0.1205]],\n\n        [[-0.0206, -0.0524,  0.1111,  0.2702],\n         [-0.1503,  0.0542,  0.0921,  0.2098],\n         [-0.2395, -0.0082,  0.1821,  0.1473],\n         [-0.1410, -0.0510,  0.1272,  0.0702],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]],\n\n        [[ 0.3011, -0.0614,  0.0943,  0.0871],\n         [ 0.2555, -0.1526,  0.1258, -0.1127],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]]], grad_fn=<TransposeBackward0>)\ntensor([5, 5, 4, 2])\n"
    }
   ],
   "source": [
    "outs, lengths = pad_packed_sequence(packed_outs, batch_first=True)\n",
    "print(outs)\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([[[-0.3265,  0.0767],\n          [ 0.1149, -0.0599],\n          [-0.1410, -0.0510],\n          [ 0.2555, -0.1526]],\n \n         [[-0.0549,  0.0859],\n          [ 0.1882,  0.0390],\n          [ 0.1111,  0.2702],\n          [ 0.0943,  0.0871]]], grad_fn=<StackBackward>),\n tensor([[[-0.5174,  0.1323],\n          [ 0.1446, -0.3065],\n          [-0.2064, -0.1436],\n          [ 0.4362, -0.5133]],\n \n         [[-0.5596,  0.1723],\n          [ 0.4508,  0.1184],\n          [ 0.3183,  0.4854],\n          [ 0.4917,  0.1074]]], grad_fn=<StackBackward>))"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM: Multi-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PackedSequence(data=tensor([[-1.4777, -1.7557,  0.0762],\n        [ 0.3904, -0.0394, -0.8015],\n        [ 1.6953,  2.0655, -0.2340],\n        [-1.2320,  0.6257, -1.2231],\n        [-1.0786,  1.4403, -0.1106],\n        [-0.4955, -0.3615,  0.5851],\n        [ 0.7073,  0.5800,  0.2683],\n        [-0.6232, -0.2162, -0.4887],\n        [ 0.5769, -0.1692, -0.0640],\n        [-1.1560, -0.1434, -0.1947],\n        [-2.0589,  0.5340, -0.5354],\n        [ 1.0384,  0.9068, -0.4755],\n        [-0.0856,  1.3945,  0.5969],\n        [-0.8637, -0.0235,  1.1717],\n        [-0.8707,  0.1447,  1.9029],\n        [-0.4828, -0.3661, -1.3271]]), batch_sizes=tensor([4, 4, 3, 3, 2]), sorted_indices=None, unsorted_indices=None)"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Specify the random seed. \n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 3 input dimensions, 2 hidden dimensions, 1 layer. \n",
    "bi_lstm = nn.LSTM(3, 2, batch_first=True, bidirectional=True, num_layers=2)\n",
    "\n",
    "# Masked input & output\n",
    "# 5 seq length, 4 batch size, 3 embedding dimensions. \n",
    "ins = torch.randn(4, 5, 3)\n",
    "\n",
    "# The sequences have to be sorted in a decreasing order according to their lengths. \n",
    "# The four sentences have 5, 5, 4, 2 valid words, respectively. \n",
    "packed_ins = pack_padded_sequence(ins, lengths=[5, 5, 4, 2], batch_first=True)\n",
    "packed_ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PackedSequence(data=tensor([[ 3.9679e-02,  3.9668e-02,  9.9274e-04, -3.3757e-01],\n        [ 4.8100e-02,  1.1329e-01,  1.9735e-02, -3.2491e-01],\n        [ 5.0718e-02,  1.4100e-01,  2.7250e-02, -3.2355e-01],\n        [ 3.7809e-02,  5.7408e-02, -1.7073e-02, -3.5471e-01],\n        [ 6.4809e-02,  9.5330e-02,  1.5299e-03, -3.6686e-01],\n        [ 6.6838e-02,  8.3767e-02,  1.1935e-02, -3.2278e-01],\n        [ 7.6019e-02,  1.6800e-01,  3.1728e-02, -3.0029e-01],\n        [ 5.6300e-02,  5.6807e-02, -1.9340e-02, -2.9829e-01],\n        [ 7.3877e-02,  1.2904e-01,  2.2365e-02, -3.2285e-01],\n        [ 7.4595e-02,  6.2288e-02, -3.5284e-03, -3.5036e-01],\n        [ 8.5724e-02,  1.0087e-01,  2.5473e-03, -3.2244e-01],\n        [ 8.4051e-02,  1.6466e-01,  2.1183e-02, -3.0374e-01],\n        [ 8.1718e-02,  1.3030e-01,  3.0468e-03, -3.4926e-01],\n        [ 8.2684e-02,  9.0221e-02, -3.1224e-04, -2.6496e-01],\n        [ 8.6588e-02,  1.2812e-01,  2.0970e-02, -2.1160e-01],\n        [ 7.0915e-02,  8.8007e-02, -5.3031e-03, -2.8080e-01]],\n       grad_fn=<CatBackward>), batch_sizes=tensor([4, 4, 3, 3, 2]), sorted_indices=None, unsorted_indices=None)"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Fisrt dim: num_layers * num_directions\n",
    "hidden = (torch.zeros(2*2, 4, 2),\n",
    "          torch.zeros(2*2, 4, 2))\n",
    "\n",
    "packed_outs, hidden = bi_lstm(packed_ins, hidden)\n",
    "packed_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[ 3.9679e-02,  3.9668e-02,  9.9274e-04, -3.3757e-01],\n         [ 6.4809e-02,  9.5330e-02,  1.5299e-03, -3.6686e-01],\n         [ 7.3877e-02,  1.2904e-01,  2.2365e-02, -3.2285e-01],\n         [ 8.4051e-02,  1.6466e-01,  2.1183e-02, -3.0374e-01],\n         [ 8.6588e-02,  1.2812e-01,  2.0970e-02, -2.1160e-01]],\n\n        [[ 4.8100e-02,  1.1329e-01,  1.9735e-02, -3.2491e-01],\n         [ 6.6838e-02,  8.3767e-02,  1.1935e-02, -3.2278e-01],\n         [ 7.4595e-02,  6.2288e-02, -3.5284e-03, -3.5036e-01],\n         [ 8.1718e-02,  1.3030e-01,  3.0468e-03, -3.4926e-01],\n         [ 7.0915e-02,  8.8007e-02, -5.3031e-03, -2.8080e-01]],\n\n        [[ 5.0718e-02,  1.4100e-01,  2.7250e-02, -3.2355e-01],\n         [ 7.6019e-02,  1.6800e-01,  3.1728e-02, -3.0029e-01],\n         [ 8.5724e-02,  1.0087e-01,  2.5473e-03, -3.2244e-01],\n         [ 8.2684e-02,  9.0221e-02, -3.1224e-04, -2.6496e-01],\n         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n\n        [[ 3.7809e-02,  5.7408e-02, -1.7073e-02, -3.5471e-01],\n         [ 5.6300e-02,  5.6807e-02, -1.9340e-02, -2.9829e-01],\n         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n       grad_fn=<TransposeBackward0>)\ntensor([5, 5, 4, 2])\n"
    }
   ],
   "source": [
    "outs, lengths = pad_packed_sequence(packed_outs, batch_first=True)\n",
    "print(outs)\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([[[-0.3424,  0.1747],\n          [ 0.1782, -0.0752],\n          [-0.0449,  0.0524],\n          [ 0.2657, -0.1505]],\n \n         [[-0.0359,  0.2987],\n          [ 0.1657,  0.0949],\n          [ 0.2546,  0.1280],\n          [ 0.1036,  0.2277]],\n \n         [[ 0.0866,  0.1281],\n          [ 0.0709,  0.0880],\n          [ 0.0827,  0.0902],\n          [ 0.0563,  0.0568]],\n \n         [[ 0.0010, -0.3376],\n          [ 0.0197, -0.3249],\n          [ 0.0273, -0.3236],\n          [-0.0171, -0.3547]]], grad_fn=<StackBackward>),\n tensor([[[-0.4188,  0.3046],\n          [ 0.2505, -0.2792],\n          [-0.0534,  0.1012],\n          [ 0.3787, -0.4299]],\n \n         [[-0.4642,  0.4800],\n          [ 0.4496,  0.1709],\n          [ 0.3041,  0.4286],\n          [ 0.4325,  0.2871]],\n \n         [[ 0.3096,  0.2118],\n          [ 0.2702,  0.1278],\n          [ 0.2827,  0.1391],\n          [ 0.1959,  0.0818]],\n \n         [[ 0.0031, -0.5341],\n          [ 0.0592, -0.5119],\n          [ 0.0822, -0.4914],\n          [-0.0508, -0.5782]]], grad_fn=<StackBackward>))"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An LSTM for Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n{'DET': 0, 'NN': 1, 'V': 2}\n"
    }
   ],
   "source": [
    "# Data\n",
    "train_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "\n",
    "word2idx = {}\n",
    "tag2idx = {}\n",
    "for sent, tags in train_data:\n",
    "    for word in sent:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "    for tag in tags:\n",
    "        if tag not in tag2idx:\n",
    "            tag2idx[tag] = len(tag2idx)\n",
    "print(word2idx)\n",
    "print(tag2idx)\n",
    "\n",
    "EMB_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "VOC_SIZE = len(word2idx)\n",
    "TAGSET_SIZE = len(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_dim, voc_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()        \n",
    "        self.word_emb = nn.Embedding(voc_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        \n",
    "        self.hidden_0 = (torch.zeros(1, 1, hidden_dim),\n",
    "                         torch.zeros(1, 1, hidden_dim))\n",
    "        \n",
    "    def forward(self, sent):\n",
    "        emb = self.word_emb(sent)\n",
    "        # Make one sentence as a batch. \n",
    "        lstm_outs, hidden = self.lstm(emb.view(1, sent.size(0), -1), self.hidden_0)\n",
    "        \n",
    "        # Scores for each word in the sentence. \n",
    "        tag_space = self.hidden2tag(lstm_outs.view(sent.size(0), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=-1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-1.4727, -1.2174, -0.7451],\n        [-1.4879, -1.1658, -0.7712],\n        [-1.4218, -1.1337, -0.8281],\n        [-1.2431, -1.0778, -0.9911],\n        [-1.3597, -1.3337, -0.7345]], grad_fn=<LogSoftmaxBackward>)\n"
    }
   ],
   "source": [
    "model = LSTMTagger(EMB_DIM, HIDDEN_DIM, VOC_SIZE, TAGSET_SIZE)\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "sent_idxes = [word2idx[w] for w in train_data[0][0]]\n",
    "sent_ins = torch.tensor(sent_idxes, dtype=torch.long)\n",
    "tag_scores = model(sent_ins)\n",
    "\n",
    "# Scores for each word in the sentence. \n",
    "print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-0.1235, -3.0423, -2.6821],\n        [-4.4550, -0.0218, -4.6157],\n        [-3.1474, -4.6781, -0.0537],\n        [-0.0183, -5.6775, -4.2190],\n        [-3.8691, -0.0278, -5.0329]], grad_fn=<LogSoftmaxBackward>)\ntensor([0, 1, 2, 0, 1], grad_fn=<NotImplemented>)\n"
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    for sent, tags in train_data:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        sent_idxes = [word2idx[w] for w in sent]\n",
    "        sent_ins = torch.tensor(sent_idxes, dtype=torch.long)\n",
    "        tag_idxes = [tag2idx[tag] for tag in tags]\n",
    "        targets = torch.tensor(tag_idxes, dtype=torch.long)\n",
    "        \n",
    "        tag_scores = model(sent_ins)\n",
    "        loss = loss_func(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "sent_idxes = [word2idx[w] for w in train_data[0][0]]\n",
    "sent_ins = torch.tensor(sent_idxes, dtype=torch.long)\n",
    "tag_scores = model(sent_ins)\n",
    "print(tag_scores)\n",
    "print(tag_scores.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0, 1, 2, 0, 1]"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "[tag2idx[t] for t in train_data[0][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: Recurrent Neural Network\n",
    "\n",
    "![RNN](fig/RNN.jpg)\n",
    "\n",
    "Math formulas: \n",
    "$$\n",
    "h_t = \\tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Parameter containing:\ntensor([[-0.0053,  0.3793, -0.5820],\n        [-0.5204, -0.2723,  0.1896]], requires_grad=True)\nParameter containing:\ntensor([[-0.0140,  0.5607],\n        [-0.0628,  0.1871]], requires_grad=True)\nParameter containing:\ntensor([-0.2137, -0.1390], requires_grad=True)\nParameter containing:\ntensor([-0.6755, -0.4683], requires_grad=True)\n"
    }
   ],
   "source": [
    "# Specify the random seed. \n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 3 input dimensions, 2 hidden dimensions, 1 layer. \n",
    "rnn = nn.RNN(3, 2)\n",
    "\n",
    "print(rnn.weight_ih_l0)\n",
    "print(rnn.weight_hh_l0)\n",
    "print(rnn.bias_ih_l0)\n",
    "print(rnn.bias_hh_l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[-0.7831,  1.0622, -0.2613]]])\ntensor([[[-0.1114, -0.4837]]], grad_fn=<StackBackward>)\ntensor([[[-0.1114, -0.4837]]], grad_fn=<StackBackward>)\n"
    }
   ],
   "source": [
    "# 1 seq length, 1 batch size, 3 embedding dimensions. \n",
    "in1 = torch.randn(1, 1, 3)\n",
    "print(in1)\n",
    "\n",
    "# Initialize the hidden state, which is h_0 in RNN structure picture. \n",
    "hidden0 = torch.randn(1, 1, 2)\n",
    "\n",
    "# Pass throught the RNN cell. \n",
    "out1, hidden1 = rnn(in1, hidden0)\n",
    "print(out1)\n",
    "print(hidden1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-0.1114, -0.4837]], grad_fn=<TanhBackward>)\n"
    }
   ],
   "source": [
    "# Manually calculate the RNN\n",
    "# Shape of (1, 2)\n",
    "W_ih_xb = in1[0].mm(rnn.weight_ih_l0.T) + rnn.bias_ih_l0\n",
    "W_hh_xb = hidden0[0].mm(rnn.weight_hh_l0.T) + rnn.bias_hh_l0\n",
    "\n",
    "# Shape of (1, 2)\n",
    "h1 = F.tanh((W_ih_xb + W_hh_xb))\n",
    "\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU: Gated Recurrent Unit\n",
    "\n",
    "![GRU](fig/RNN-vs-LSTM-vs-GRU.jpg)\n",
    "\n",
    "Math formulas: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "r_t &= \\mathrm{sigmoid}(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n",
    "z_t &= \\mathrm{sigmoid}(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n",
    "n_t &= \\tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n",
    "h_t &= (1 - z_t) * n_t + z_t * h_{(t-1)} \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Parameter containing:\ntensor([[-0.0053,  0.3793, -0.5820],\n        [-0.5204, -0.2723,  0.1896],\n        [-0.0140,  0.5607, -0.0628],\n        [ 0.1871, -0.2137, -0.1390],\n        [-0.6755, -0.4683, -0.2915],\n        [ 0.0262,  0.2795,  0.4243]], requires_grad=True)\nParameter containing:\ntensor([[-0.4794, -0.3079],\n        [ 0.2568,  0.5872],\n        [-0.1455,  0.5291],\n        [-0.1140,  0.0748],\n        [ 0.6403, -0.6560],\n        [-0.4452, -0.1790]], requires_grad=True)\nParameter containing:\ntensor([-0.2756,  0.6109, -0.4583, -0.3255, -0.4940, -0.6622],\n       requires_grad=True)\nParameter containing:\ntensor([-0.4128,  0.6078,  0.3155,  0.3427,  0.0372, -0.3625],\n       requires_grad=True)\n"
    }
   ],
   "source": [
    "# Specify the random seed. \n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 3 input dimensions, 2 hidden dimensions, 1 layer. \n",
    "gru = nn.GRU(3, 2)\n",
    "\n",
    "# (W_ir|W_iz|W_in)\n",
    "print(gru.weight_ih_l0)\n",
    "# (W_hr|W_hz|W_hn)\n",
    "print(gru.weight_hh_l0)\n",
    "# (b_ir|b_iz|b_in)\n",
    "print(gru.bias_ih_l0)\n",
    "# (b_hr|b_hz|b_hn)\n",
    "print(gru.bias_hh_l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[-0.2142, -0.4320, -0.7079]]])\ntensor([[[ 0.2779, -1.0391]]], grad_fn=<StackBackward>)\ntensor([[[ 0.2779, -1.0391]]], grad_fn=<StackBackward>)\n"
    }
   ],
   "source": [
    "# 1 seq length, 1 batch size, 3 embedding dimensions. \n",
    "in1 = torch.randn(1, 1, 3)\n",
    "print(in1)\n",
    "\n",
    "# Initialize the hidden state, which is h_0 in GRU structure picture. \n",
    "hidden0 = torch.randn(1, 1, 2)\n",
    "\n",
    "# Pass throught the GRU cell. \n",
    "out1, hidden1 = gru(in1, hidden0)\n",
    "print(out1)\n",
    "print(hidden1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 0.2779, -1.0391]], grad_fn=<AddBackward0>)\n"
    }
   ],
   "source": [
    "# Manually calculate the GRU\n",
    "# Shape of (1, 2*3)\n",
    "W_ih_xb = in1[0].mm(gru.weight_ih_l0.T) + gru.bias_ih_l0\n",
    "W_hh_xb = hidden0[0].mm(gru.weight_hh_l0.T) + gru.bias_hh_l0\n",
    "\n",
    "# Shape of (1, 2)\n",
    "r1 = F.sigmoid((W_ih_xb + W_hh_xb)[:, 0:2])\n",
    "z1 = F.sigmoid((W_ih_xb + W_hh_xb)[:, 2:4])\n",
    "n1 = F.tanh(W_ih_xb[:, 4:6] + r1 * W_hh_xb[:, 4:6])\n",
    "h1 = (1 - z1) * n1 + z1 * hidden0[0]\n",
    "\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}